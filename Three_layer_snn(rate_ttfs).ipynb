{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import neuron\n",
    "import linear\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# check gpu\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modify here if you use other datasets\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "input_dimmension = 784                 # input feature의 개수 (MNIST : 784)\n",
    "hidden_dimmension = 100                # hidden layer 개수\n",
    "output_dimmension = 10                 # output label 개수 (MNIST : 10)\n",
    "# if you want to use other dataset\n",
    "#data_path = './WineQT.csv'             # dataset이 저장되어있는 경로 // dataset이 csv파일이고 마지막 feature가 output label이라고 가정\n",
    "\n",
    "\n",
    "# 임의의 dataset을 사용하기 위해 만든 class\n",
    "class SNN_Dataset(Dataset):\n",
    "  def __init__(self, csv_path):\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    self.x_data = df.iloc[:, :-1].values\n",
    "    self.y_data = df.iloc[:, -1].values\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.x_data)\n",
    "  def __getitem__(self, idx):\n",
    "    return self.x_data[idx], self.y_data[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nearly all paramters in this simulation, but it seems no use to store them in a dict...\n",
    "param = {'G_min': -1.0, # the minimum (maximum) value of conductance, I found if I use real conductance value\n",
    "        'G_max': 1.0,   # which is on 1e-4 level, the gradience will be too small even in two layer net.\n",
    "        'Rd': 10e9,    # this device resistance is mannually set for smaller leaky current?\n",
    "        'Cm': 80e-12,   # real capacitance is absolutely larger than this valu\n",
    "        'Rs': 1205000,      # this series resistance value is mannually set for larger inject current?\n",
    "        'Vth': 3.6,     # this is the real device threshould voltage\n",
    "        'V_reset': 3.7,\n",
    "        'dt': 1.75e-4,   # every time step is dt, in the one-order differential equation of neuron\n",
    "        'T_sim': 50,   # could control total spike number collected\n",
    "        'dim_in': input_dimmension,\n",
    "        'dim_h': hidden_dimmension,\n",
    "        'dim_out': output_dimmension,\n",
    "        'amp' : 3,    # the gain of TIAs\n",
    "        'q_bit': 7,    # quantize bit\n",
    "        'epoch': 100,\n",
    "        'batch_size': 2000,\n",
    "        'learning_rate': 0.022,\n",
    "        'data_dir': './MNIST',\n",
    "        'train_file': 'trainning_log_7bit.txt',\n",
    "        'test_file': 'test_log.txt',\n",
    "        'model_dir': 'Model.pth'\n",
    "}\n",
    "\n",
    "def rate_encoding(x, T_sim):\n",
    "    '''\n",
    "    Encodes the input image pixels into periodic spike trains.\n",
    "    \n",
    "    input : x (batch_size, dim_in) - input data\n",
    "           T_sim (int) - number of time steps for the simulation\n",
    "    output : (batch_size, dim_in, T_sim) - periodic spikes for each pixel over T_sim time steps\n",
    "    '''\n",
    "    \n",
    "    batch_size, dim_in = x.shape\n",
    "    spikes = torch.zeros(batch_size, dim_in, T_sim).to(x.device)\n",
    "\n",
    "    # Data directly obtained through research\n",
    "    pixel_values = torch.tensor([0, 0.287273, 0.389091, 0.592727, 0.796364, 1]).to(x.device)\n",
    "    periods = torch.tensor([6.5, 3.1, 2.6, 2.2, 1.9, 1.7]).to(x.device)\n",
    "    \n",
    "    period = torch.zeros_like(x)\n",
    "    for i in range(len(pixel_values) - 1):\n",
    "        mask = (x >= pixel_values[i]) & (x < pixel_values[i+1])\n",
    "        period[mask] = periods[i] + (periods[i+1] - periods[i]) * (x[mask] - pixel_values[i]) / (pixel_values[i+1] - pixel_values[i])\n",
    "    period[x == 1] = 1.7\n",
    "\n",
    "    for t in range(T_sim):\n",
    "        spikes[:, :, t] = ((t+1) // period > t // period)\n",
    "    return spikes\n",
    "\n",
    "\n",
    "def ttfs_encoding(x, T_sim):\n",
    "    '''\n",
    "    Encodes the input image pixels using time-to-first-spike encoding based on provided data.\n",
    "\n",
    "    input: x (batch_size, dim_in) - input data\n",
    "           T_sim (int) - number of time steps for the simulation\n",
    "    output: (batch_size, dim_in, T_sim) - time-to-first-spike encoded spikes\n",
    "    '''\n",
    "    \n",
    "    batch_size, dim_in = x.shape\n",
    "    spikes = torch.zeros(batch_size, dim_in, T_sim).to(x.device)\n",
    "\n",
    "    # Data directly obtained through research\n",
    "    pixel_values = torch.tensor([0, 0.287273, 0.389091, 0.592727, 0.796364, 1]).to(x.device)\n",
    "    spike_times = torch.tensor([14.3, 12.4, 11.8, 11.4, 11.3, 11.2]).to(x.device) \n",
    "    \n",
    "    spike_times = spike_times - 11.2  # starts after 11.2ms for efficient model training\n",
    "    spike_time = torch.zeros_like(x)\n",
    "    \n",
    "    for i in range(len(pixel_values) - 1):\n",
    "        mask = (x >= pixel_values[i]) & (x < pixel_values[i+1])\n",
    "        spike_time[mask] = spike_times[i] + (spike_times[i+1] - spike_times[i]) * (x[mask] - pixel_values[i]) / (pixel_values[i+1] - pixel_values[i])\n",
    "    spike_time[x == 1] = spike_times[-1]\n",
    "    \n",
    "    for t in range(T_sim):\n",
    "        spikes[:, :, t] = (spike_time < t + 1).float() * (spike_time >= t).float()\n",
    "    return spikes\n",
    "\n",
    "    \n",
    "class Three_Layer_SNN(nn.Module):\n",
    "    '''\n",
    "    This net model contains 2 linear layer, 2 self-defined BatchNorm layer and 2 Neuron layer.\n",
    "\n",
    "    linear layer: a memristor crossbar on which the MAC operation is implemented.\n",
    "    BatchNorm layer: a row of TIA as the output interface of the pre-linear layer, normalize the\n",
    "                    output current to  -2.0~2.0 V voltage.\n",
    "    neuron layer: nonliear activation, receive input voltage and output spikes, spiking rate is taken\n",
    "                    in loss computing.\n",
    "    '''\n",
    "    def __init__(self, param):\n",
    "        super().__init__()\n",
    "        self.linear1 = linear.MAC_Crossbar(param['dim_in'], param['dim_h'],\n",
    "                                            param['G_min'], param['G_max'], param['q_bit'])\n",
    "        self.BatchNorm1 = linear.TIA_Norm(param['dim_in'], 0.0, 200.0)    # the paramters of TIA are mannually set for moderate input voltage to neurons\n",
    "        self.neuron1 = neuron.LIFNeuron(param['batch_size'], param['dim_h'], param['Rd'], param['Cm'],\n",
    "                                            param['Rs'], param['Vth'], param['V_reset'], param['dt'])\n",
    "        self.linear2 = linear.MAC_Crossbar(param['dim_h'], param['dim_out'],\n",
    "                                            param['G_min'], param['G_max'], param['q_bit'])\n",
    "        self.BatchNorm2 = linear.TIA_Norm(param['dim_h'], 0.0, 200.0)    # same as above\n",
    "        self.neuron2 = neuron.LIFNeuron(param['batch_size'], param['dim_out'], param['Rd'], param['Cm'],\n",
    "                                            param['Rs'], param['Vth'], param['V_reset'], param['dt'])\n",
    "\n",
    "    def forward(self, input_vector):\n",
    "        total_spikes = 0 # total spike count\n",
    "        \n",
    "        out_vector = self.linear1(input_vector)\n",
    "        out_vector = self.BatchNorm1(out_vector)\n",
    "\n",
    "        self.neuron1.v = self.neuron1.v.to(device)\n",
    "        self.neuron2.v = self.neuron2.v.to(device)\n",
    "\n",
    "        out_vector = self.neuron1(out_vector)\n",
    "        total_spikes += torch.sum(out_vector == 1).item()\n",
    "        \n",
    "        out_vector = self.linear2(out_vector)\n",
    "        out_vector = self.BatchNorm2(out_vector)\n",
    "        out_vector = self.neuron2(out_vector)\n",
    "        total_spikes += torch.sum(out_vector == 1).item()\n",
    "        \n",
    "        return out_vector, total_spikes\n",
    "\n",
    "    def reset_(self):\n",
    "        '''\n",
    "        Reset all neurons after one forward pass,\n",
    "        to ensure the independency of every input image.\n",
    "        '''\n",
    "        for item in self.modules():\n",
    "            if hasattr(item, 'reset'):\n",
    "                item.reset()\n",
    "\n",
    "    def quant_(self):\n",
    "        '''\n",
    "        The quantization function in pytorch only support int8,\n",
    "        so we need our own quant function for adjustable quantization precision.\n",
    "        '''\n",
    "        for item in self.modules():\n",
    "            if hasattr(item, 'Gquant_'):\n",
    "                #debug print：\n",
    "                #print(item.weight.max())\n",
    "                item.Gquant_()\n",
    "                #debug print：\n",
    "                #print(item.weight.max())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tranning epoch 0: the SNN loss is 2.132565 trainning accuracy: 0.4099 validation accuracy: 0.7145\n",
      "average spike number : 8664 elapsed time : 3.8s\n",
      "tranning epoch 1: the SNN loss is 2.078736 trainning accuracy: 0.7643 validation accuracy: 0.8093\n",
      "average spike number : 8599 elapsed time : 7.5s\n",
      "tranning epoch 2: the SNN loss is 2.063942 trainning accuracy: 0.8186 validation accuracy: 0.8394\n",
      "average spike number : 8590 elapsed time : 11.1s\n",
      "tranning epoch 3: the SNN loss is 2.055650 trainning accuracy: 0.8423 validation accuracy: 0.8554\n",
      "average spike number : 8574 elapsed time : 14.8s\n",
      "tranning epoch 4: the SNN loss is 2.047132 trainning accuracy: 0.8576 validation accuracy: 0.8659\n",
      "average spike number : 8575 elapsed time : 18.4s\n",
      "tranning epoch 5: the SNN loss is 2.042633 trainning accuracy: 0.8677 validation accuracy: 0.8724\n",
      "average spike number : 8579 elapsed time : 22.0s\n",
      "tranning epoch 6: the SNN loss is 2.036709 trainning accuracy: 0.8754 validation accuracy: 0.8799\n",
      "average spike number : 8573 elapsed time : 25.6s\n",
      "tranning epoch 7: the SNN loss is 2.032498 trainning accuracy: 0.8800 validation accuracy: 0.8775\n",
      "average spike number : 8584 elapsed time : 29.2s\n",
      "tranning epoch 8: the SNN loss is 2.029389 trainning accuracy: 0.8836 validation accuracy: 0.8837\n",
      "average spike number : 8580 elapsed time : 32.8s\n",
      "tranning epoch 9: the SNN loss is 2.031478 trainning accuracy: 0.8884 validation accuracy: 0.8897\n",
      "average spike number : 8587 elapsed time : 36.4s\n",
      "tranning epoch 10: the SNN loss is 2.026519 trainning accuracy: 0.8915 validation accuracy: 0.8882\n",
      "average spike number : 8586 elapsed time : 40.1s\n",
      "tranning epoch 11: the SNN loss is 2.025204 trainning accuracy: 0.8941 validation accuracy: 0.8932\n",
      "average spike number : 8586 elapsed time : 43.7s\n",
      "tranning epoch 12: the SNN loss is 2.025846 trainning accuracy: 0.8955 validation accuracy: 0.8939\n",
      "average spike number : 8594 elapsed time : 47.4s\n",
      "tranning epoch 13: the SNN loss is 2.022287 trainning accuracy: 0.8986 validation accuracy: 0.8986\n",
      "average spike number : 8598 elapsed time : 51.0s\n",
      "tranning epoch 14: the SNN loss is 2.019830 trainning accuracy: 0.9010 validation accuracy: 0.8971\n",
      "average spike number : 8587 elapsed time : 54.6s\n",
      "tranning epoch 15: the SNN loss is 2.016170 trainning accuracy: 0.9016 validation accuracy: 0.9016\n",
      "average spike number : 8587 elapsed time : 58.2s\n",
      "tranning epoch 16: the SNN loss is 2.022123 trainning accuracy: 0.9032 validation accuracy: 0.8993\n",
      "average spike number : 8597 elapsed time : 61.9s\n",
      "tranning epoch 17: the SNN loss is 2.018677 trainning accuracy: 0.9056 validation accuracy: 0.9011\n",
      "average spike number : 8598 elapsed time : 65.6s\n",
      "tranning epoch 18: the SNN loss is 2.016535 trainning accuracy: 0.9058 validation accuracy: 0.9032\n",
      "average spike number : 8606 elapsed time : 69.2s\n",
      "tranning epoch 19: the SNN loss is 2.016651 trainning accuracy: 0.9069 validation accuracy: 0.9003\n",
      "average spike number : 8595 elapsed time : 72.9s\n",
      "tranning epoch 20: the SNN loss is 2.014323 trainning accuracy: 0.9078 validation accuracy: 0.9032\n",
      "average spike number : 8601 elapsed time : 76.5s\n",
      "tranning epoch 21: the SNN loss is 2.019100 trainning accuracy: 0.9085 validation accuracy: 0.8990\n",
      "average spike number : 8606 elapsed time : 80.2s\n",
      "tranning epoch 22: the SNN loss is 2.016656 trainning accuracy: 0.9096 validation accuracy: 0.9024\n",
      "average spike number : 8603 elapsed time : 83.8s\n",
      "tranning epoch 23: the SNN loss is 2.013184 trainning accuracy: 0.9106 validation accuracy: 0.9013\n",
      "average spike number : 8607 elapsed time : 87.4s\n",
      "tranning epoch 24: the SNN loss is 2.011521 trainning accuracy: 0.9110 validation accuracy: 0.9004\n",
      "average spike number : 8600 elapsed time : 91.1s\n",
      "tranning epoch 25: the SNN loss is 2.013217 trainning accuracy: 0.9128 validation accuracy: 0.9006\n",
      "average spike number : 8608 elapsed time : 94.7s\n",
      "tranning epoch 26: the SNN loss is 2.013404 trainning accuracy: 0.9124 validation accuracy: 0.9042\n",
      "average spike number : 8608 elapsed time : 98.4s\n",
      "tranning epoch 27: the SNN loss is 2.011613 trainning accuracy: 0.9140 validation accuracy: 0.9036\n",
      "average spike number : 8605 elapsed time : 102.0s\n",
      "tranning epoch 28: the SNN loss is 2.011763 trainning accuracy: 0.9149 validation accuracy: 0.9017\n",
      "average spike number : 8609 elapsed time : 105.5s\n",
      "tranning epoch 29: the SNN loss is 2.009521 trainning accuracy: 0.9138 validation accuracy: 0.9030\n",
      "average spike number : 8606 elapsed time : 109.2s\n",
      "tranning epoch 30: the SNN loss is 2.014141 trainning accuracy: 0.9153 validation accuracy: 0.9037\n",
      "average spike number : 8613 elapsed time : 112.9s\n",
      "tranning epoch 31: the SNN loss is 2.011165 trainning accuracy: 0.9154 validation accuracy: 0.9030\n",
      "average spike number : 8610 elapsed time : 116.4s\n",
      "tranning epoch 32: the SNN loss is 2.006268 trainning accuracy: 0.9161 validation accuracy: 0.9028\n",
      "average spike number : 8614 elapsed time : 120.0s\n",
      "tranning epoch 33: the SNN loss is 2.008539 trainning accuracy: 0.9159 validation accuracy: 0.9032\n",
      "average spike number : 8616 elapsed time : 123.6s\n",
      "tranning epoch 34: the SNN loss is 2.011171 trainning accuracy: 0.9165 validation accuracy: 0.9039\n",
      "average spike number : 8606 elapsed time : 127.2s\n",
      "tranning epoch 35: the SNN loss is 2.006428 trainning accuracy: 0.9175 validation accuracy: 0.9053\n",
      "average spike number : 8611 elapsed time : 130.8s\n",
      "tranning epoch 36: the SNN loss is 2.006335 trainning accuracy: 0.9172 validation accuracy: 0.9053\n",
      "average spike number : 8609 elapsed time : 134.4s\n",
      "tranning epoch 37: the SNN loss is 2.009347 trainning accuracy: 0.9171 validation accuracy: 0.9055\n",
      "average spike number : 8612 elapsed time : 138.0s\n",
      "tranning epoch 38: the SNN loss is 2.007184 trainning accuracy: 0.9176 validation accuracy: 0.9062\n",
      "average spike number : 8611 elapsed time : 141.6s\n",
      "tranning epoch 39: the SNN loss is 2.008622 trainning accuracy: 0.9184 validation accuracy: 0.9052\n",
      "average spike number : 8608 elapsed time : 145.2s\n",
      "tranning epoch 40: the SNN loss is 2.007008 trainning accuracy: 0.9184 validation accuracy: 0.9052\n",
      "average spike number : 8612 elapsed time : 148.8s\n",
      "tranning epoch 41: the SNN loss is 2.009885 trainning accuracy: 0.9185 validation accuracy: 0.9039\n",
      "average spike number : 8611 elapsed time : 152.5s\n",
      "tranning epoch 42: the SNN loss is 2.006014 trainning accuracy: 0.9195 validation accuracy: 0.9034\n",
      "average spike number : 8605 elapsed time : 156.1s\n",
      "tranning epoch 43: the SNN loss is 2.008120 trainning accuracy: 0.9197 validation accuracy: 0.9062\n",
      "average spike number : 8607 elapsed time : 159.7s\n",
      "tranning epoch 44: the SNN loss is 2.004648 trainning accuracy: 0.9193 validation accuracy: 0.9069\n",
      "average spike number : 8614 elapsed time : 163.3s\n",
      "tranning epoch 45: the SNN loss is 2.006418 trainning accuracy: 0.9195 validation accuracy: 0.9058\n",
      "average spike number : 8608 elapsed time : 167.0s\n",
      "tranning epoch 46: the SNN loss is 2.004447 trainning accuracy: 0.9203 validation accuracy: 0.9086\n",
      "average spike number : 8611 elapsed time : 170.6s\n",
      "tranning epoch 47: the SNN loss is 2.006790 trainning accuracy: 0.9210 validation accuracy: 0.9038\n",
      "average spike number : 8618 elapsed time : 174.2s\n",
      "tranning epoch 48: the SNN loss is 2.004263 trainning accuracy: 0.9209 validation accuracy: 0.9052\n",
      "average spike number : 8609 elapsed time : 177.8s\n",
      "tranning epoch 49: the SNN loss is 2.008258 trainning accuracy: 0.9204 validation accuracy: 0.9054\n",
      "average spike number : 8610 elapsed time : 181.4s\n",
      "tranning epoch 50: the SNN loss is 2.006181 trainning accuracy: 0.9214 validation accuracy: 0.9064\n",
      "average spike number : 8612 elapsed time : 185.0s\n",
      "tranning epoch 51: the SNN loss is 2.004595 trainning accuracy: 0.9206 validation accuracy: 0.9062\n",
      "average spike number : 8613 elapsed time : 188.6s\n",
      "tranning epoch 52: the SNN loss is 2.007273 trainning accuracy: 0.9215 validation accuracy: 0.9076\n",
      "average spike number : 8613 elapsed time : 192.3s\n",
      "tranning epoch 53: the SNN loss is 2.006794 trainning accuracy: 0.9218 validation accuracy: 0.9061\n",
      "average spike number : 8611 elapsed time : 195.9s\n",
      "tranning epoch 54: the SNN loss is 2.006352 trainning accuracy: 0.9223 validation accuracy: 0.9065\n",
      "average spike number : 8613 elapsed time : 199.5s\n",
      "tranning epoch 55: the SNN loss is 2.005058 trainning accuracy: 0.9226 validation accuracy: 0.9072\n",
      "average spike number : 8620 elapsed time : 203.1s\n",
      "tranning epoch 56: the SNN loss is 2.004169 trainning accuracy: 0.9223 validation accuracy: 0.9072\n",
      "average spike number : 8615 elapsed time : 206.7s\n",
      "tranning epoch 57: the SNN loss is 2.005187 trainning accuracy: 0.9227 validation accuracy: 0.9068\n",
      "average spike number : 8613 elapsed time : 210.4s\n",
      "tranning epoch 58: the SNN loss is 2.003606 trainning accuracy: 0.9223 validation accuracy: 0.9051\n",
      "average spike number : 8614 elapsed time : 214.0s\n",
      "tranning epoch 59: the SNN loss is 2.004465 trainning accuracy: 0.9227 validation accuracy: 0.9067\n",
      "average spike number : 8621 elapsed time : 217.6s\n",
      "tranning epoch 60: the SNN loss is 2.000895 trainning accuracy: 0.9230 validation accuracy: 0.9080\n",
      "average spike number : 8611 elapsed time : 221.3s\n",
      "tranning epoch 61: the SNN loss is 2.005383 trainning accuracy: 0.9231 validation accuracy: 0.9070\n",
      "average spike number : 8611 elapsed time : 224.9s\n",
      "tranning epoch 62: the SNN loss is 2.004078 trainning accuracy: 0.9241 validation accuracy: 0.9049\n",
      "average spike number : 8615 elapsed time : 228.5s\n",
      "tranning epoch 63: the SNN loss is 2.002791 trainning accuracy: 0.9239 validation accuracy: 0.9072\n",
      "average spike number : 8611 elapsed time : 232.2s\n",
      "tranning epoch 64: the SNN loss is 2.002833 trainning accuracy: 0.9234 validation accuracy: 0.9089\n",
      "average spike number : 8606 elapsed time : 235.8s\n",
      "tranning epoch 65: the SNN loss is 2.003999 trainning accuracy: 0.9234 validation accuracy: 0.9092\n",
      "average spike number : 8617 elapsed time : 239.3s\n",
      "tranning epoch 66: the SNN loss is 2.005145 trainning accuracy: 0.9247 validation accuracy: 0.9078\n",
      "average spike number : 8616 elapsed time : 242.9s\n",
      "tranning epoch 67: the SNN loss is 2.003552 trainning accuracy: 0.9239 validation accuracy: 0.9107\n",
      "average spike number : 8612 elapsed time : 246.6s\n",
      "tranning epoch 68: the SNN loss is 2.001723 trainning accuracy: 0.9246 validation accuracy: 0.9105\n",
      "average spike number : 8618 elapsed time : 250.2s\n",
      "tranning epoch 69: the SNN loss is 2.004340 trainning accuracy: 0.9236 validation accuracy: 0.9077\n",
      "average spike number : 8614 elapsed time : 253.8s\n",
      "tranning epoch 70: the SNN loss is 1.999002 trainning accuracy: 0.9239 validation accuracy: 0.9087\n",
      "average spike number : 8617 elapsed time : 257.5s\n",
      "tranning epoch 71: the SNN loss is 2.005267 trainning accuracy: 0.9247 validation accuracy: 0.9100\n",
      "average spike number : 8614 elapsed time : 261.1s\n",
      "tranning epoch 72: the SNN loss is 2.002671 trainning accuracy: 0.9247 validation accuracy: 0.9090\n",
      "average spike number : 8620 elapsed time : 264.7s\n",
      "tranning epoch 73: the SNN loss is 2.002461 trainning accuracy: 0.9250 validation accuracy: 0.9092\n",
      "average spike number : 8618 elapsed time : 268.3s\n",
      "tranning epoch 74: the SNN loss is 1.999892 trainning accuracy: 0.9250 validation accuracy: 0.9095\n",
      "average spike number : 8623 elapsed time : 272.0s\n",
      "tranning epoch 75: the SNN loss is 2.000959 trainning accuracy: 0.9237 validation accuracy: 0.9094\n",
      "average spike number : 8614 elapsed time : 275.5s\n",
      "tranning epoch 76: the SNN loss is 2.003175 trainning accuracy: 0.9251 validation accuracy: 0.9080\n",
      "average spike number : 8618 elapsed time : 279.1s\n",
      "tranning epoch 77: the SNN loss is 2.003205 trainning accuracy: 0.9253 validation accuracy: 0.9100\n",
      "average spike number : 8618 elapsed time : 282.7s\n",
      "tranning epoch 78: the SNN loss is 2.001463 trainning accuracy: 0.9256 validation accuracy: 0.9098\n",
      "average spike number : 8616 elapsed time : 286.4s\n",
      "tranning epoch 79: the SNN loss is 2.002660 trainning accuracy: 0.9253 validation accuracy: 0.9085\n",
      "average spike number : 8619 elapsed time : 290.0s\n",
      "tranning epoch 80: the SNN loss is 1.999691 trainning accuracy: 0.9254 validation accuracy: 0.9093\n",
      "average spike number : 8619 elapsed time : 293.6s\n",
      "tranning epoch 81: the SNN loss is 2.000535 trainning accuracy: 0.9254 validation accuracy: 0.9119\n",
      "average spike number : 8616 elapsed time : 297.2s\n",
      "tranning epoch 82: the SNN loss is 2.002861 trainning accuracy: 0.9258 validation accuracy: 0.9095\n",
      "average spike number : 8617 elapsed time : 300.8s\n",
      "tranning epoch 83: the SNN loss is 2.000112 trainning accuracy: 0.9263 validation accuracy: 0.9103\n",
      "average spike number : 8617 elapsed time : 304.5s\n",
      "tranning epoch 84: the SNN loss is 1.999300 trainning accuracy: 0.9274 validation accuracy: 0.9081\n",
      "average spike number : 8616 elapsed time : 308.1s\n",
      "tranning epoch 85: the SNN loss is 2.000882 trainning accuracy: 0.9271 validation accuracy: 0.9088\n",
      "average spike number : 8615 elapsed time : 311.7s\n",
      "tranning epoch 86: the SNN loss is 2.001339 trainning accuracy: 0.9264 validation accuracy: 0.9103\n",
      "average spike number : 8615 elapsed time : 315.3s\n",
      "tranning epoch 87: the SNN loss is 1.999176 trainning accuracy: 0.9268 validation accuracy: 0.9096\n",
      "average spike number : 8621 elapsed time : 318.9s\n",
      "tranning epoch 88: the SNN loss is 1.999493 trainning accuracy: 0.9268 validation accuracy: 0.9086\n",
      "average spike number : 8614 elapsed time : 322.6s\n",
      "tranning epoch 89: the SNN loss is 1.999293 trainning accuracy: 0.9266 validation accuracy: 0.9094\n",
      "average spike number : 8617 elapsed time : 326.2s\n",
      "tranning epoch 90: the SNN loss is 1.999725 trainning accuracy: 0.9264 validation accuracy: 0.9097\n",
      "average spike number : 8613 elapsed time : 329.8s\n",
      "tranning epoch 91: the SNN loss is 2.001238 trainning accuracy: 0.9269 validation accuracy: 0.9103\n",
      "average spike number : 8614 elapsed time : 333.4s\n",
      "tranning epoch 92: the SNN loss is 2.001744 trainning accuracy: 0.9262 validation accuracy: 0.9086\n",
      "average spike number : 8615 elapsed time : 337.1s\n",
      "tranning epoch 93: the SNN loss is 1.999502 trainning accuracy: 0.9264 validation accuracy: 0.9108\n",
      "average spike number : 8620 elapsed time : 340.7s\n",
      "tranning epoch 94: the SNN loss is 2.000402 trainning accuracy: 0.9260 validation accuracy: 0.9095\n",
      "average spike number : 8623 elapsed time : 344.4s\n",
      "tranning epoch 95: the SNN loss is 2.002348 trainning accuracy: 0.9261 validation accuracy: 0.9095\n",
      "average spike number : 8614 elapsed time : 348.0s\n",
      "tranning epoch 96: the SNN loss is 2.000052 trainning accuracy: 0.9263 validation accuracy: 0.9113\n",
      "average spike number : 8619 elapsed time : 351.6s\n",
      "tranning epoch 97: the SNN loss is 2.000246 trainning accuracy: 0.9272 validation accuracy: 0.9097\n",
      "average spike number : 8618 elapsed time : 355.2s\n",
      "tranning epoch 98: the SNN loss is 1.999245 trainning accuracy: 0.9264 validation accuracy: 0.9119\n",
      "average spike number : 8615 elapsed time : 358.8s\n",
      "tranning epoch 99: the SNN loss is 2.002269 trainning accuracy: 0.9265 validation accuracy: 0.9116\n",
      "average spike number : 8615 elapsed time : 362.3s\n"
     ]
    }
   ],
   "source": [
    "# Rate Encoding 방식으로 model을 학습\n",
    "# Time_step = 50, learning_rate = 0.013, average_spike = 8591, test_accuracy = 91%\n",
    "\n",
    "trainset = torchvision.datasets.MNIST(root=param['data_dir'], train=True,\n",
    "                                        download=True, transform=transforms.ToTensor())\n",
    "testset = torchvision.datasets.MNIST(root=param['data_dir'], train=False,\n",
    "                                        download=True, transform=transforms.ToTensor())\n",
    "trainloader = torch.utils.data.DataLoader(dataset=trainset, batch_size=param['batch_size'],\n",
    "                                            shuffle=True, drop_last=True, num_workers=2, pin_memory=True)\n",
    "testloader = torch.utils.data.DataLoader(dataset=testset, batch_size=param['batch_size'],\n",
    "                                            shuffle=False, drop_last=True, num_workers=2, pin_memory=True)\n",
    "\n",
    "#Train the SNN with BP\n",
    "net = Three_Layer_SNN(param).to(device)\n",
    "loss_func = torch.nn.CrossEntropyLoss().to(device)\n",
    "optim = torch.optim.Adam(net.parameters(), param['learning_rate'])\n",
    "\n",
    "start = time.time()\n",
    "for epoch in range(param['epoch']):\n",
    "    net.train()\n",
    "    train_accuracy = []\n",
    "    \n",
    "    for img, label in trainloader:\n",
    "        img = img.reshape(-1, input_dimmension)\n",
    "        spike_num_img = torch.zeros(param['batch_size'], param['dim_out']).to(device)\n",
    "\n",
    "        # using gpu\n",
    "        img, label = img.to(device), label.to(device)\n",
    "    \n",
    "        # rate coding method\n",
    "        spike_time = rate_encoding(img, param['T_sim'])\n",
    "\n",
    "        net.reset_() #set the neuron voltage as reset voltage\n",
    "        for t in range(param['T_sim']):\n",
    "            # rate coding method\n",
    "            new_img = spike_time[:, :, t]  \n",
    "            out_spike, total_spike = net(new_img)\n",
    "            spike_num_img += out_spike \n",
    "\n",
    "        spike_rate = spike_num_img/param['T_sim'] \n",
    "        loss = loss_func(spike_rate, label)\n",
    "\n",
    "        #net.zero_grad()\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            net.reset_()    # reset the neuron voltage every batch, to ensure independency between batchs\n",
    "            net.quant_()    # quantize the weights after weight update\n",
    "\n",
    "        train_accuracy.append((spike_rate.max(1)[1] == label).float().mean().item())\n",
    "    accuracy_epoch = np.mean(train_accuracy)\n",
    "    print('tranning epoch %d: the SNN loss is %.6f' %(epoch, loss), end=' ')\n",
    "    print('trainning accuracy: %.4f' %accuracy_epoch, end=' ')\n",
    "    \n",
    "# validation by testset every epoch to see if the network is overfitted\n",
    "    net.eval()\n",
    "    validation_accuracy = []\n",
    "    with torch.no_grad():\n",
    "        total_spike = 0\n",
    "        for img_test, label_test in testloader:\n",
    "            img_test = img_test.reshape(-1, input_dimmension)\n",
    "            spike_num_img_test = torch.zeros(param['batch_size'], param['dim_out']).to(device)\n",
    "\n",
    "            # using gpu\n",
    "            img_test, label_test = img_test.to(device), label_test.to(device)\n",
    "\n",
    "            # rate coding method\n",
    "            spike_time = rate_encoding(img_test, param['T_sim'])\n",
    "            \n",
    "            total_spike += spike_time.sum()\n",
    "            net.reset_() #set the neuron voltage as reset voltage\n",
    "            for t in range(param['T_sim']):\n",
    "                # rate coding method\n",
    "                new_test_img = spike_time[:, :, t]  \n",
    "                out_spike, spike_num = net(new_test_img)\n",
    "                spike_num_img_test += out_spike \n",
    "                total_spike += spike_num\n",
    "                \n",
    "            validation_accuracy.append((spike_num_img_test.max(1)[1]==label_test).float().mean().item())\n",
    "        accuracy_val = np.mean(validation_accuracy)\n",
    "        total_spike = int(total_spike / len(testloader.dataset))\n",
    "        print('validation accuracy: %.4f' %accuracy_val)\n",
    "        print('average spike number : {}' .format(total_spike), end = \" \") \n",
    "        print('elapsed time : {0:.1f}s' .format(time.time() - start))\n",
    "\n",
    "    with open(param['train_file'], 'a') as f_t:\n",
    "        s = str(epoch).ljust(6, ' ') + str(round(loss.item(), 6)).ljust(12, ' ')\n",
    "        s += str(round(accuracy_epoch, 4)).ljust(10, ' ') + str(round(accuracy_val, 4)).ljust(10, ' ')\n",
    "        s += str(total_spike).ljust(12, ' ') + '\\n'\n",
    "        f_t.write(s)\n",
    "\n",
    "torch.save(net.state_dict(), param['model_dir'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pixel Values: tensor([[0.0000, 0.0101, 0.0202, 0.0303, 0.0404, 0.0505, 0.0606, 0.0707, 0.0808,\n",
      "         0.0909, 0.1010, 0.1111, 0.1212, 0.1313, 0.1414, 0.1515, 0.1616, 0.1717,\n",
      "         0.1818, 0.1919, 0.2020, 0.2121, 0.2222, 0.2323, 0.2424, 0.2525, 0.2626,\n",
      "         0.2727, 0.2828, 0.2929, 0.3030, 0.3131, 0.3232, 0.3333, 0.3434, 0.3535,\n",
      "         0.3636, 0.3737, 0.3838, 0.3939, 0.4040, 0.4141, 0.4242, 0.4343, 0.4444,\n",
      "         0.4545, 0.4646, 0.4747, 0.4848, 0.4949, 0.5051, 0.5152, 0.5253, 0.5354,\n",
      "         0.5455, 0.5556, 0.5657, 0.5758, 0.5859, 0.5960, 0.6061, 0.6162, 0.6263,\n",
      "         0.6364, 0.6465, 0.6566, 0.6667, 0.6768, 0.6869, 0.6970, 0.7071, 0.7172,\n",
      "         0.7273, 0.7374, 0.7475, 0.7576, 0.7677, 0.7778, 0.7879, 0.7980, 0.8081,\n",
      "         0.8182, 0.8283, 0.8384, 0.8485, 0.8586, 0.8687, 0.8788, 0.8889, 0.8990,\n",
      "         0.9091, 0.9192, 0.9293, 0.9394, 0.9495, 0.9596, 0.9697, 0.9798, 0.9899,\n",
      "         1.0000]])\n",
      "\n",
      " ttfe with acquired data :\n",
      "Pixel 0.0: Spikes at time step(s) [3]\n",
      "Pixel 0.010101010091602802: Spikes at time step(s) [3]\n",
      "Pixel 0.020202020183205605: Spikes at time step(s) [2]\n",
      "Pixel 0.03030303120613098: Spikes at time step(s) [2]\n",
      "Pixel 0.04040404036641121: Spikes at time step(s) [2]\n",
      "Pixel 0.05050504952669144: Spikes at time step(s) [2]\n",
      "Pixel 0.06060606241226196: Spikes at time step(s) [2]\n",
      "Pixel 0.07070706784725189: Spikes at time step(s) [2]\n",
      "Pixel 0.08080808073282242: Spikes at time step(s) [2]\n",
      "Pixel 0.09090909361839294: Spikes at time step(s) [2]\n",
      "Pixel 0.10101009905338287: Spikes at time step(s) [2]\n",
      "Pixel 0.1111111119389534: Spikes at time step(s) [2]\n",
      "Pixel 0.12121212482452393: Spikes at time step(s) [2]\n",
      "Pixel 0.13131313025951385: Spikes at time step(s) [2]\n",
      "Pixel 0.14141413569450378: Spikes at time step(s) [2]\n",
      "Pixel 0.1515151560306549: Spikes at time step(s) [2]\n",
      "Pixel 0.16161616146564484: Spikes at time step(s) [2]\n",
      "Pixel 0.17171716690063477: Spikes at time step(s) [1]\n",
      "Pixel 0.1818181872367859: Spikes at time step(s) [1]\n",
      "Pixel 0.19191919267177582: Spikes at time step(s) [1]\n",
      "Pixel 0.20202019810676575: Spikes at time step(s) [1]\n",
      "Pixel 0.21212121844291687: Spikes at time step(s) [1]\n",
      "Pixel 0.2222222238779068: Spikes at time step(s) [1]\n",
      "Pixel 0.23232322931289673: Spikes at time step(s) [1]\n",
      "Pixel 0.24242424964904785: Spikes at time step(s) [1]\n",
      "Pixel 0.2525252401828766: Spikes at time step(s) [1]\n",
      "Pixel 0.2626262605190277: Spikes at time step(s) [1]\n",
      "Pixel 0.27272728085517883: Spikes at time step(s) [1]\n",
      "Pixel 0.28282827138900757: Spikes at time step(s) [1]\n",
      "Pixel 0.2929292917251587: Spikes at time step(s) [1]\n",
      "Pixel 0.3030303120613098: Spikes at time step(s) [1]\n",
      "Pixel 0.31313130259513855: Spikes at time step(s) [1]\n",
      "Pixel 0.3232323229312897: Spikes at time step(s) [0]\n",
      "Pixel 0.3333333432674408: Spikes at time step(s) [0]\n",
      "Pixel 0.34343433380126953: Spikes at time step(s) [0]\n",
      "Pixel 0.35353535413742065: Spikes at time step(s) [0]\n",
      "Pixel 0.3636363744735718: Spikes at time step(s) [0]\n",
      "Pixel 0.3737373650074005: Spikes at time step(s) [0]\n",
      "Pixel 0.38383838534355164: Spikes at time step(s) [0]\n",
      "Pixel 0.39393940567970276: Spikes at time step(s) [0]\n",
      "Pixel 0.4040403962135315: Spikes at time step(s) [0]\n",
      "Pixel 0.4141414165496826: Spikes at time step(s) [0]\n",
      "Pixel 0.42424243688583374: Spikes at time step(s) [0]\n",
      "Pixel 0.4343434274196625: Spikes at time step(s) [0]\n",
      "Pixel 0.4444444477558136: Spikes at time step(s) [0]\n",
      "Pixel 0.4545454680919647: Spikes at time step(s) [0]\n",
      "Pixel 0.46464645862579346: Spikes at time step(s) [0]\n",
      "Pixel 0.4747474789619446: Spikes at time step(s) [0]\n",
      "Pixel 0.4848484992980957: Spikes at time step(s) [0]\n",
      "Pixel 0.49494948983192444: Spikes at time step(s) [0]\n",
      "Pixel 0.5050504803657532: Spikes at time step(s) [0]\n",
      "Pixel 0.5151515007019043: Spikes at time step(s) [0]\n",
      "Pixel 0.5252525210380554: Spikes at time step(s) [0]\n",
      "Pixel 0.5353535413742065: Spikes at time step(s) [0]\n",
      "Pixel 0.5454545617103577: Spikes at time step(s) [0]\n",
      "Pixel 0.5555555820465088: Spikes at time step(s) [0]\n",
      "Pixel 0.5656565427780151: Spikes at time step(s) [0]\n",
      "Pixel 0.5757575631141663: Spikes at time step(s) [0]\n",
      "Pixel 0.5858585834503174: Spikes at time step(s) [0]\n",
      "Pixel 0.5959596037864685: Spikes at time step(s) [0]\n",
      "Pixel 0.6060606241226196: Spikes at time step(s) [0]\n",
      "Pixel 0.6161616444587708: Spikes at time step(s) [0]\n",
      "Pixel 0.6262626051902771: Spikes at time step(s) [0]\n",
      "Pixel 0.6363636255264282: Spikes at time step(s) [0]\n",
      "Pixel 0.6464646458625793: Spikes at time step(s) [0]\n",
      "Pixel 0.6565656661987305: Spikes at time step(s) [0]\n",
      "Pixel 0.6666666865348816: Spikes at time step(s) [0]\n",
      "Pixel 0.6767677068710327: Spikes at time step(s) [0]\n",
      "Pixel 0.6868686676025391: Spikes at time step(s) [0]\n",
      "Pixel 0.6969696879386902: Spikes at time step(s) [0]\n",
      "Pixel 0.7070707082748413: Spikes at time step(s) [0]\n",
      "Pixel 0.7171717286109924: Spikes at time step(s) [0]\n",
      "Pixel 0.7272727489471436: Spikes at time step(s) [0]\n",
      "Pixel 0.7373737096786499: Spikes at time step(s) [0]\n",
      "Pixel 0.747474730014801: Spikes at time step(s) [0]\n",
      "Pixel 0.7575757503509521: Spikes at time step(s) [0]\n",
      "Pixel 0.7676767706871033: Spikes at time step(s) [0]\n",
      "Pixel 0.7777777910232544: Spikes at time step(s) [0]\n",
      "Pixel 0.7878788113594055: Spikes at time step(s) [0]\n",
      "Pixel 0.7979797720909119: Spikes at time step(s) [0]\n",
      "Pixel 0.808080792427063: Spikes at time step(s) [0]\n",
      "Pixel 0.8181818127632141: Spikes at time step(s) [0]\n",
      "Pixel 0.8282828330993652: Spikes at time step(s) [0]\n",
      "Pixel 0.8383838534355164: Spikes at time step(s) [0]\n",
      "Pixel 0.8484848737716675: Spikes at time step(s) [0]\n",
      "Pixel 0.8585858345031738: Spikes at time step(s) [0]\n",
      "Pixel 0.868686854839325: Spikes at time step(s) [0]\n",
      "Pixel 0.8787878751754761: Spikes at time step(s) [0]\n",
      "Pixel 0.8888888955116272: Spikes at time step(s) [0]\n",
      "Pixel 0.8989899158477783: Spikes at time step(s) [0]\n",
      "Pixel 0.9090909361839294: Spikes at time step(s) [0]\n",
      "Pixel 0.9191918969154358: Spikes at time step(s) [0]\n",
      "Pixel 0.9292929172515869: Spikes at time step(s) [0]\n",
      "Pixel 0.939393937587738: Spikes at time step(s) [0]\n",
      "Pixel 0.9494949579238892: Spikes at time step(s) [0]\n",
      "Pixel 0.9595959782600403: Spikes at time step(s) [0]\n",
      "Pixel 0.9696969985961914: Spikes at time step(s) [0]\n",
      "Pixel 0.9797979593276978: Spikes at time step(s) [0]\n",
      "Pixel 0.9898989796638489: Spikes at time step(s) [0]\n",
      "Pixel 1.0: Spikes at time step(s) [0]\n"
     ]
    }
   ],
   "source": [
    "# time-to-first-spike encoding 방식을 통해 encdoing 했을 때 spike가 어떻게 발생하는 지 디버깅하기 위한 부분\n",
    "\n",
    "# 픽셀 값 생성 (0 ~ 1)\n",
    "pixel_values = torch.linspace(0, 1, 100).reshape(1, -1).to('cpu')  #(batch_size, dim_in)\n",
    "print(\"Pixel Values:\", pixel_values)\n",
    "\n",
    "# 직접 구한 데이터를 이용해 ttfs 방식으로 encoding\n",
    "spike_time = ttfs_encoding(pixel_values, param['T_sim'])\n",
    "\n",
    "print(\"\\n ttfe with acquired data :\")\n",
    "for i in range(spike_time.shape[1]):\n",
    "    spike_times = torch.nonzero(spike_time[0, i, :]).flatten()\n",
    "    print(f\"Pixel {pixel_values[0, i].item()}: Spikes at time step(s) {spike_times.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tranning epoch 0: the SNN loss is 1.736727 trainning accuracy: 0.3723 validation accuracy: 0.5991\n",
      "average spike number : 867 elapsed time : 3.7s\n",
      "tranning epoch 1: the SNN loss is 1.657020 trainning accuracy: 0.6530 validation accuracy: 0.6884\n",
      "average spike number : 869 elapsed time : 7.5s\n",
      "tranning epoch 2: the SNN loss is 1.627377 trainning accuracy: 0.7085 validation accuracy: 0.7393\n",
      "average spike number : 868 elapsed time : 11.2s\n",
      "tranning epoch 3: the SNN loss is 1.619920 trainning accuracy: 0.7502 validation accuracy: 0.7652\n",
      "average spike number : 868 elapsed time : 14.9s\n",
      "tranning epoch 4: the SNN loss is 1.613176 trainning accuracy: 0.7665 validation accuracy: 0.7725\n",
      "average spike number : 867 elapsed time : 18.6s\n",
      "tranning epoch 5: the SNN loss is 1.604881 trainning accuracy: 0.7908 validation accuracy: 0.7698\n",
      "average spike number : 867 elapsed time : 22.3s\n",
      "tranning epoch 6: the SNN loss is 1.594854 trainning accuracy: 0.7968 validation accuracy: 0.7952\n",
      "average spike number : 866 elapsed time : 26.1s\n",
      "tranning epoch 7: the SNN loss is 1.564671 trainning accuracy: 0.8143 validation accuracy: 0.7996\n",
      "average spike number : 867 elapsed time : 29.7s\n",
      "tranning epoch 8: the SNN loss is 1.573352 trainning accuracy: 0.8192 validation accuracy: 0.8060\n",
      "average spike number : 867 elapsed time : 33.4s\n",
      "tranning epoch 9: the SNN loss is 1.561543 trainning accuracy: 0.8316 validation accuracy: 0.8111\n",
      "average spike number : 867 elapsed time : 37.2s\n",
      "tranning epoch 10: the SNN loss is 1.556357 trainning accuracy: 0.8345 validation accuracy: 0.8217\n",
      "average spike number : 867 elapsed time : 40.8s\n",
      "tranning epoch 11: the SNN loss is 1.553496 trainning accuracy: 0.8441 validation accuracy: 0.8235\n",
      "average spike number : 867 elapsed time : 44.5s\n",
      "tranning epoch 12: the SNN loss is 1.555226 trainning accuracy: 0.8513 validation accuracy: 0.8324\n",
      "average spike number : 868 elapsed time : 48.2s\n",
      "tranning epoch 13: the SNN loss is 1.551174 trainning accuracy: 0.8585 validation accuracy: 0.8317\n",
      "average spike number : 868 elapsed time : 52.0s\n",
      "tranning epoch 14: the SNN loss is 1.551932 trainning accuracy: 0.8592 validation accuracy: 0.8386\n",
      "average spike number : 868 elapsed time : 55.7s\n",
      "tranning epoch 15: the SNN loss is 1.566067 trainning accuracy: 0.8629 validation accuracy: 0.8421\n",
      "average spike number : 868 elapsed time : 59.3s\n",
      "tranning epoch 16: the SNN loss is 1.548338 trainning accuracy: 0.8700 validation accuracy: 0.8388\n",
      "average spike number : 868 elapsed time : 63.0s\n",
      "tranning epoch 17: the SNN loss is 1.540276 trainning accuracy: 0.8683 validation accuracy: 0.8418\n",
      "average spike number : 869 elapsed time : 66.7s\n",
      "tranning epoch 18: the SNN loss is 1.526167 trainning accuracy: 0.8762 validation accuracy: 0.8416\n",
      "average spike number : 869 elapsed time : 70.4s\n",
      "tranning epoch 19: the SNN loss is 1.538453 trainning accuracy: 0.8780 validation accuracy: 0.8525\n",
      "average spike number : 868 elapsed time : 74.1s\n",
      "tranning epoch 20: the SNN loss is 1.536512 trainning accuracy: 0.8837 validation accuracy: 0.8415\n",
      "average spike number : 869 elapsed time : 77.8s\n",
      "tranning epoch 21: the SNN loss is 1.534919 trainning accuracy: 0.8826 validation accuracy: 0.8476\n",
      "average spike number : 869 elapsed time : 81.4s\n",
      "tranning epoch 22: the SNN loss is 1.534536 trainning accuracy: 0.8858 validation accuracy: 0.8531\n",
      "average spike number : 869 elapsed time : 85.1s\n",
      "tranning epoch 23: the SNN loss is 1.526523 trainning accuracy: 0.8929 validation accuracy: 0.8524\n",
      "average spike number : 869 elapsed time : 88.8s\n",
      "tranning epoch 24: the SNN loss is 1.529083 trainning accuracy: 0.8948 validation accuracy: 0.8548\n",
      "average spike number : 868 elapsed time : 92.6s\n",
      "tranning epoch 25: the SNN loss is 1.521308 trainning accuracy: 0.8984 validation accuracy: 0.8633\n",
      "average spike number : 869 elapsed time : 96.3s\n",
      "tranning epoch 26: the SNN loss is 1.535137 trainning accuracy: 0.8974 validation accuracy: 0.8633\n",
      "average spike number : 869 elapsed time : 100.0s\n",
      "tranning epoch 27: the SNN loss is 1.531202 trainning accuracy: 0.9017 validation accuracy: 0.8564\n",
      "average spike number : 870 elapsed time : 103.7s\n",
      "tranning epoch 28: the SNN loss is 1.513766 trainning accuracy: 0.9008 validation accuracy: 0.8591\n",
      "average spike number : 869 elapsed time : 107.5s\n",
      "tranning epoch 29: the SNN loss is 1.531183 trainning accuracy: 0.9030 validation accuracy: 0.8650\n",
      "average spike number : 870 elapsed time : 111.2s\n",
      "tranning epoch 30: the SNN loss is 1.517752 trainning accuracy: 0.9031 validation accuracy: 0.8621\n",
      "average spike number : 870 elapsed time : 114.8s\n",
      "tranning epoch 31: the SNN loss is 1.518544 trainning accuracy: 0.9068 validation accuracy: 0.8612\n",
      "average spike number : 869 elapsed time : 118.5s\n",
      "tranning epoch 32: the SNN loss is 1.516247 trainning accuracy: 0.9071 validation accuracy: 0.8607\n",
      "average spike number : 869 elapsed time : 122.2s\n",
      "tranning epoch 33: the SNN loss is 1.516843 trainning accuracy: 0.9085 validation accuracy: 0.8703\n",
      "average spike number : 869 elapsed time : 125.8s\n",
      "tranning epoch 34: the SNN loss is 1.516594 trainning accuracy: 0.9141 validation accuracy: 0.8671\n",
      "average spike number : 869 elapsed time : 129.5s\n",
      "tranning epoch 35: the SNN loss is 1.514212 trainning accuracy: 0.9164 validation accuracy: 0.8741\n",
      "average spike number : 869 elapsed time : 133.2s\n",
      "tranning epoch 36: the SNN loss is 1.509361 trainning accuracy: 0.9173 validation accuracy: 0.8712\n",
      "average spike number : 869 elapsed time : 136.9s\n",
      "tranning epoch 37: the SNN loss is 1.516968 trainning accuracy: 0.9192 validation accuracy: 0.8718\n",
      "average spike number : 869 elapsed time : 140.6s\n",
      "tranning epoch 38: the SNN loss is 1.510064 trainning accuracy: 0.9209 validation accuracy: 0.8747\n",
      "average spike number : 869 elapsed time : 144.2s\n",
      "tranning epoch 39: the SNN loss is 1.513712 trainning accuracy: 0.9234 validation accuracy: 0.8704\n",
      "average spike number : 869 elapsed time : 147.9s\n",
      "tranning epoch 40: the SNN loss is 1.510040 trainning accuracy: 0.9212 validation accuracy: 0.8762\n",
      "average spike number : 869 elapsed time : 151.6s\n",
      "tranning epoch 41: the SNN loss is 1.513260 trainning accuracy: 0.9223 validation accuracy: 0.8740\n",
      "average spike number : 869 elapsed time : 155.3s\n",
      "tranning epoch 42: the SNN loss is 1.504111 trainning accuracy: 0.9226 validation accuracy: 0.8717\n",
      "average spike number : 870 elapsed time : 159.0s\n",
      "tranning epoch 43: the SNN loss is 1.507340 trainning accuracy: 0.9238 validation accuracy: 0.8748\n",
      "average spike number : 870 elapsed time : 162.7s\n",
      "tranning epoch 44: the SNN loss is 1.507694 trainning accuracy: 0.9251 validation accuracy: 0.8794\n",
      "average spike number : 869 elapsed time : 166.3s\n",
      "tranning epoch 45: the SNN loss is 1.505000 trainning accuracy: 0.9273 validation accuracy: 0.8749\n",
      "average spike number : 871 elapsed time : 170.0s\n",
      "tranning epoch 46: the SNN loss is 1.510678 trainning accuracy: 0.9269 validation accuracy: 0.8751\n",
      "average spike number : 870 elapsed time : 173.6s\n",
      "tranning epoch 47: the SNN loss is 1.506458 trainning accuracy: 0.9283 validation accuracy: 0.8784\n",
      "average spike number : 870 elapsed time : 177.3s\n",
      "tranning epoch 48: the SNN loss is 1.506387 trainning accuracy: 0.9290 validation accuracy: 0.8794\n",
      "average spike number : 870 elapsed time : 181.0s\n",
      "tranning epoch 49: the SNN loss is 1.510353 trainning accuracy: 0.9285 validation accuracy: 0.8791\n",
      "average spike number : 870 elapsed time : 184.7s\n",
      "tranning epoch 50: the SNN loss is 1.499749 trainning accuracy: 0.9307 validation accuracy: 0.8824\n",
      "average spike number : 870 elapsed time : 188.4s\n",
      "tranning epoch 51: the SNN loss is 1.502429 trainning accuracy: 0.9350 validation accuracy: 0.8796\n",
      "average spike number : 870 elapsed time : 192.1s\n",
      "tranning epoch 52: the SNN loss is 1.503841 trainning accuracy: 0.9335 validation accuracy: 0.8841\n",
      "average spike number : 870 elapsed time : 195.8s\n",
      "tranning epoch 53: the SNN loss is 1.513863 trainning accuracy: 0.9347 validation accuracy: 0.8789\n",
      "average spike number : 870 elapsed time : 199.5s\n",
      "tranning epoch 54: the SNN loss is 1.505152 trainning accuracy: 0.9354 validation accuracy: 0.8826\n",
      "average spike number : 870 elapsed time : 203.2s\n",
      "tranning epoch 55: the SNN loss is 1.507579 trainning accuracy: 0.9342 validation accuracy: 0.8840\n",
      "average spike number : 871 elapsed time : 206.9s\n",
      "tranning epoch 56: the SNN loss is 1.503712 trainning accuracy: 0.9349 validation accuracy: 0.8792\n",
      "average spike number : 870 elapsed time : 210.7s\n",
      "tranning epoch 57: the SNN loss is 1.499885 trainning accuracy: 0.9347 validation accuracy: 0.8832\n",
      "average spike number : 870 elapsed time : 214.5s\n",
      "tranning epoch 58: the SNN loss is 1.500653 trainning accuracy: 0.9370 validation accuracy: 0.8818\n",
      "average spike number : 870 elapsed time : 218.2s\n",
      "tranning epoch 59: the SNN loss is 1.490278 trainning accuracy: 0.9367 validation accuracy: 0.8873\n",
      "average spike number : 871 elapsed time : 221.9s\n",
      "tranning epoch 60: the SNN loss is 1.499226 trainning accuracy: 0.9390 validation accuracy: 0.8834\n",
      "average spike number : 870 elapsed time : 225.6s\n",
      "tranning epoch 61: the SNN loss is 1.499259 trainning accuracy: 0.9389 validation accuracy: 0.8884\n",
      "average spike number : 870 elapsed time : 229.3s\n",
      "tranning epoch 62: the SNN loss is 1.500389 trainning accuracy: 0.9365 validation accuracy: 0.8861\n",
      "average spike number : 870 elapsed time : 233.0s\n",
      "tranning epoch 63: the SNN loss is 1.500274 trainning accuracy: 0.9338 validation accuracy: 0.8816\n",
      "average spike number : 871 elapsed time : 236.7s\n",
      "tranning epoch 64: the SNN loss is 1.501258 trainning accuracy: 0.9363 validation accuracy: 0.8860\n",
      "average spike number : 871 elapsed time : 240.4s\n",
      "tranning epoch 65: the SNN loss is 1.499821 trainning accuracy: 0.9380 validation accuracy: 0.8835\n",
      "average spike number : 872 elapsed time : 244.1s\n",
      "tranning epoch 66: the SNN loss is 1.500473 trainning accuracy: 0.9368 validation accuracy: 0.8824\n",
      "average spike number : 871 elapsed time : 247.8s\n",
      "tranning epoch 67: the SNN loss is 1.499942 trainning accuracy: 0.9380 validation accuracy: 0.8849\n",
      "average spike number : 870 elapsed time : 251.5s\n",
      "tranning epoch 68: the SNN loss is 1.489693 trainning accuracy: 0.9371 validation accuracy: 0.8849\n",
      "average spike number : 871 elapsed time : 255.2s\n",
      "tranning epoch 69: the SNN loss is 1.497877 trainning accuracy: 0.9396 validation accuracy: 0.8808\n",
      "average spike number : 870 elapsed time : 258.9s\n",
      "tranning epoch 70: the SNN loss is 1.495029 trainning accuracy: 0.9389 validation accuracy: 0.8890\n",
      "average spike number : 871 elapsed time : 262.5s\n",
      "tranning epoch 71: the SNN loss is 1.495760 trainning accuracy: 0.9357 validation accuracy: 0.8837\n",
      "average spike number : 871 elapsed time : 266.3s\n",
      "tranning epoch 72: the SNN loss is 1.495940 trainning accuracy: 0.9412 validation accuracy: 0.8910\n",
      "average spike number : 871 elapsed time : 270.1s\n",
      "tranning epoch 73: the SNN loss is 1.492852 trainning accuracy: 0.9449 validation accuracy: 0.8902\n",
      "average spike number : 871 elapsed time : 273.9s\n",
      "tranning epoch 74: the SNN loss is 1.492147 trainning accuracy: 0.9450 validation accuracy: 0.8927\n",
      "average spike number : 872 elapsed time : 277.6s\n",
      "tranning epoch 75: the SNN loss is 1.490603 trainning accuracy: 0.9459 validation accuracy: 0.8873\n",
      "average spike number : 871 elapsed time : 281.3s\n",
      "tranning epoch 76: the SNN loss is 1.497300 trainning accuracy: 0.9466 validation accuracy: 0.8945\n",
      "average spike number : 870 elapsed time : 285.0s\n",
      "tranning epoch 77: the SNN loss is 1.494075 trainning accuracy: 0.9462 validation accuracy: 0.8907\n",
      "average spike number : 870 elapsed time : 288.6s\n",
      "tranning epoch 78: the SNN loss is 1.492521 trainning accuracy: 0.9470 validation accuracy: 0.8879\n",
      "average spike number : 870 elapsed time : 292.3s\n",
      "tranning epoch 79: the SNN loss is 1.495196 trainning accuracy: 0.9483 validation accuracy: 0.8926\n",
      "average spike number : 870 elapsed time : 296.0s\n",
      "tranning epoch 80: the SNN loss is 1.493710 trainning accuracy: 0.9441 validation accuracy: 0.8888\n",
      "average spike number : 871 elapsed time : 299.7s\n",
      "tranning epoch 81: the SNN loss is 1.491674 trainning accuracy: 0.9414 validation accuracy: 0.8942\n",
      "average spike number : 870 elapsed time : 303.4s\n",
      "tranning epoch 82: the SNN loss is 1.494672 trainning accuracy: 0.9455 validation accuracy: 0.8907\n",
      "average spike number : 870 elapsed time : 307.1s\n",
      "tranning epoch 83: the SNN loss is 1.496916 trainning accuracy: 0.9469 validation accuracy: 0.8938\n",
      "average spike number : 870 elapsed time : 310.9s\n",
      "tranning epoch 84: the SNN loss is 1.493144 trainning accuracy: 0.9456 validation accuracy: 0.8921\n",
      "average spike number : 870 elapsed time : 314.6s\n",
      "tranning epoch 85: the SNN loss is 1.501942 trainning accuracy: 0.9461 validation accuracy: 0.8933\n",
      "average spike number : 871 elapsed time : 318.3s\n",
      "tranning epoch 86: the SNN loss is 1.494134 trainning accuracy: 0.9481 validation accuracy: 0.8900\n",
      "average spike number : 870 elapsed time : 322.0s\n",
      "tranning epoch 87: the SNN loss is 1.491467 trainning accuracy: 0.9467 validation accuracy: 0.8860\n",
      "average spike number : 870 elapsed time : 325.8s\n",
      "tranning epoch 88: the SNN loss is 1.498892 trainning accuracy: 0.9464 validation accuracy: 0.8906\n",
      "average spike number : 870 elapsed time : 329.6s\n",
      "tranning epoch 89: the SNN loss is 1.497205 trainning accuracy: 0.9476 validation accuracy: 0.8894\n",
      "average spike number : 870 elapsed time : 333.5s\n",
      "tranning epoch 90: the SNN loss is 1.486732 trainning accuracy: 0.9472 validation accuracy: 0.8919\n",
      "average spike number : 870 elapsed time : 337.4s\n",
      "tranning epoch 91: the SNN loss is 1.495587 trainning accuracy: 0.9438 validation accuracy: 0.8881\n",
      "average spike number : 870 elapsed time : 341.1s\n",
      "tranning epoch 92: the SNN loss is 1.497696 trainning accuracy: 0.9473 validation accuracy: 0.8904\n",
      "average spike number : 870 elapsed time : 344.8s\n",
      "tranning epoch 93: the SNN loss is 1.489575 trainning accuracy: 0.9479 validation accuracy: 0.8919\n",
      "average spike number : 869 elapsed time : 348.6s\n",
      "tranning epoch 94: the SNN loss is 1.490733 trainning accuracy: 0.9470 validation accuracy: 0.8911\n",
      "average spike number : 870 elapsed time : 352.3s\n",
      "tranning epoch 95: the SNN loss is 1.490337 trainning accuracy: 0.9517 validation accuracy: 0.8937\n",
      "average spike number : 869 elapsed time : 356.0s\n",
      "tranning epoch 96: the SNN loss is 1.484141 trainning accuracy: 0.9533 validation accuracy: 0.8982\n",
      "average spike number : 870 elapsed time : 359.7s\n",
      "tranning epoch 97: the SNN loss is 1.485743 trainning accuracy: 0.9569 validation accuracy: 0.8920\n",
      "average spike number : 870 elapsed time : 363.3s\n",
      "tranning epoch 98: the SNN loss is 1.485944 trainning accuracy: 0.9546 validation accuracy: 0.8902\n",
      "average spike number : 870 elapsed time : 367.0s\n",
      "tranning epoch 99: the SNN loss is 1.485943 trainning accuracy: 0.9549 validation accuracy: 0.8967\n",
      "average spike number : 870 elapsed time : 370.8s\n"
     ]
    }
   ],
   "source": [
    "# Time-to-first-spike encoding \n",
    "# Time_step = 50, batch_size = 2000, learning_rate = 0.022, average_spike = 871, test_accuracy = 89%\n",
    "\n",
    "trainset = torchvision.datasets.MNIST(root=param['data_dir'], train=True,\n",
    "                                        download=True, transform=transforms.ToTensor())\n",
    "testset = torchvision.datasets.MNIST(root=param['data_dir'], train=False,\n",
    "                                        download=True, transform=transforms.ToTensor())\n",
    "trainloader = torch.utils.data.DataLoader(dataset=trainset, batch_size=param['batch_size'],\n",
    "                                            shuffle=True, drop_last=True, num_workers=2, pin_memory=True)\n",
    "testloader = torch.utils.data.DataLoader(dataset=testset, batch_size=param['batch_size'],\n",
    "                                            shuffle=False, drop_last=True, num_workers=2, pin_memory=True)\n",
    "\n",
    "#Train the SNN with BP\n",
    "net = Three_Layer_SNN(param).to(device)\n",
    "loss_func = torch.nn.CrossEntropyLoss().to(device)\n",
    "optim = torch.optim.Adam(net.parameters(), param['learning_rate'])\n",
    "\n",
    "start = time.time()\n",
    "for epoch in range(param['epoch']):\n",
    "    net.train()\n",
    "    train_accuracy = []\n",
    "    \n",
    "    for img, label in trainloader:\n",
    "        img = img.reshape(-1, input_dimmension)\n",
    "        spike_num_img = torch.zeros(param['batch_size'], param['dim_out']).to(device)\n",
    "\n",
    "        # using gpu\n",
    "        img, label = img.to(device), label.to(device)\n",
    "        \n",
    "        # Time-to-first spike coding method\n",
    "        #spike_time = latency(img, num_steps=param['T_sim'], tau=10, threshold=0.01, clip=False, normalize=False, linear=False, bypass=True)\n",
    "        spike_time = ttfs_encoding(img, param['T_sim'])\n",
    "        mask = torch.ones(param['batch_size'], 1).to(device)\n",
    "\n",
    "        net.reset_() #set the neuron voltage as reset voltage\n",
    "        for t in range(param['T_sim']):\n",
    "            # Time-to-first spike coding method\n",
    "            #new_img = spike_time[t]\n",
    "            new_img = spike_time[:, :, t]  \n",
    "            out_spike, _ = net(new_img)\n",
    "            out_spike *= mask\n",
    "            spike_num_img += out_spike\n",
    "            # update mask\n",
    "            spike_detected = torch.any(out_spike > 0, dim=1, keepdim=True) \n",
    "            mask = mask * (~spike_detected) \n",
    "        spike_rate = spike_num_img\n",
    "        loss = loss_func(spike_rate, label)\n",
    "\n",
    "        #net.zero_grad()\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            net.reset_()    # reset the neuron voltage every batch, to ensure independency between batchs\n",
    "            net.quant_()    # quantize the weights after weight update\n",
    "\n",
    "        train_accuracy.append((spike_rate.max(1)[1] == label).float().mean().item())\n",
    "        \n",
    "    accuracy_epoch = np.mean(train_accuracy)\n",
    "    print('tranning epoch %d: the SNN loss is %.6f' %(epoch, loss), end=' ')\n",
    "    print('trainning accuracy: %.4f' %accuracy_epoch, end=' ')\n",
    "    \n",
    "# validation by testset every epoch to see if the network is overfitted\n",
    "    net.eval()\n",
    "    validation_accuracy = []\n",
    "    with torch.no_grad():\n",
    "        total_spike = 0\n",
    "        for img_test, label_test in testloader:\n",
    "            img_test = img_test.reshape(-1, input_dimmension)\n",
    "            spike_num_img_test = torch.zeros(param['batch_size'], param['dim_out']).to(device)\n",
    "\n",
    "            # using gpu\n",
    "            img_test, label_test = img_test.to(device), label_test.to(device)\n",
    "            \n",
    "            # Time-to-first spike coding method\n",
    "            spike_time = ttfs_encoding(img_test, param['T_sim'])\n",
    "            mask = torch.ones(param['batch_size'], 1).to(device)\n",
    "            \n",
    "            total_spike += spike_time.sum()\n",
    "            net.reset_() #set the neuron voltage as reset voltage\n",
    "            for t in range(param['T_sim']):\n",
    "                # Time-to-first spike coding method\n",
    "                # new_test_img = spike_time[t]\n",
    "                new_test_img = spike_time[:, :, t]\n",
    "                out_spike, spike_num = net(new_test_img)\n",
    "                out_spike *= mask\n",
    "                spike_num_img_test += out_spike\n",
    "                \n",
    "                # update mask\n",
    "                spike_detected = torch.any(out_spike > 0, dim=1, keepdim=True) \n",
    "                mask = mask * (~spike_detected) \n",
    "                total_spike += spike_num\n",
    "                \n",
    "            validation_accuracy.append((spike_num_img_test.max(1)[1]==label_test).float().mean().item())\n",
    "        accuracy_val = np.mean(validation_accuracy)\n",
    "        total_spike = int(total_spike / len(testloader.dataset))\n",
    "        print('validation accuracy: %.4f' %accuracy_val)\n",
    "        print('average spike number : {}' .format(total_spike), end = \" \") \n",
    "        print('elapsed time : {0:.1f}s' .format(time.time() - start))\n",
    "\n",
    "    with open(param['train_file'], 'a') as f_t:\n",
    "        s = str(epoch).ljust(6, ' ') + str(round(loss.item(), 6)).ljust(12, ' ')\n",
    "        s += str(round(accuracy_epoch, 4)).ljust(10, ' ') + str(round(accuracy_val, 4)).ljust(10, ' ')\n",
    "        s += str(total_spike).ljust(12, ' ') + '\\n'\n",
    "        f_t.write(s)\n",
    "\n",
    "torch.save(net.state_dict(), param['model_dir'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Model, please wait......\n",
      "Model loaded successfully!\n",
      "Test Accuracy: 89.67%\n"
     ]
    }
   ],
   "source": [
    "# Test process after training\n",
    "net_test = Three_Layer_SNN(param).to(device)\n",
    "print('Loading Model, please wait......')\n",
    "net_test.load_state_dict(torch.load(param['model_dir'], weights_only=True))\n",
    "print('Model loaded successfully!')\n",
    "list_num_spike = []\n",
    "for i in range(10):\n",
    "    list_num_spike.append([0])\n",
    "    list_num_spike[i].append(torch.zeros(param['dim_out']))\n",
    "\n",
    "total_correct = 0  # 전체 맞춘 예측 수\n",
    "total_samples = 0  # 전체 테스트 샘플 수\n",
    "\n",
    "with torch.no_grad():\n",
    "    for img_test, label_test in testloader:\n",
    "        img_test = img_test.reshape(-1, 28 * 28)\n",
    "        spike_num_img_test = torch.zeros(param['batch_size'], param['dim_out']).to(device)\n",
    "        net_test.reset_()  # set the neuron voltage as reset voltage\n",
    "\n",
    "        # using gpu\n",
    "        img_test, label_test = img_test.to(device), label_test.to(device)\n",
    "\n",
    "        # Time-to-first spike coding method\n",
    "        spike_time = ttfs_encoding(img_test, param['T_sim'])\n",
    "        mask = torch.ones(param['batch_size'], 1).to(device)\n",
    "        net.reset_()  # set the neuron voltage as reset voltage\n",
    "\n",
    "        for t in range(param['T_sim']):\n",
    "            #new_test_img = spike_time[t]\n",
    "            new_test_img = spike_time[:, :, t]\n",
    "            out_spike, _ = net_test(new_test_img)\n",
    "            out_spike *= mask\n",
    "            spike_num_img_test += out_spike\n",
    "            # update mask\n",
    "            spike_detected = torch.any(out_spike > 0, dim=1, keepdim=True)\n",
    "            mask = mask * (~spike_detected)\n",
    "\n",
    "        pred_label = F.one_hot(spike_num_img_test.max(1)[1], num_classes=10).to('cpu')  # convert the max neuron output index to onehot vector\n",
    "\n",
    "        # Accuracy calculation\n",
    "        pred_label_class = spike_num_img_test.max(1)[1]  # predicted class for each image in the batch\n",
    "        total_correct += (pred_label_class == label_test).sum().item()  # count correct predictions\n",
    "        total_samples += label_test.size(0)  # update total samples\n",
    "\n",
    "        for j in range(label_test.size(0)):\n",
    "            index = label_test[j]\n",
    "            list_num_spike[index][0] += 1\n",
    "            list_num_spike[index][1] += pred_label[j].to('cpu')  # statistics of prediction for every input image\n",
    "\n",
    "# Calculate and print overall accuracy\n",
    "accuracy = total_correct / total_samples * 100\n",
    "print(f'Test Accuracy: {accuracy:.2f}%')\n",
    "\n",
    "# Save confusion matrix\n",
    "with open('confusion_matrix.txt', 'a') as f2:\n",
    "    for i in range(len(list_num_spike)):\n",
    "        s = str(list_num_spike[i][0]) + ' ' + str(list_num_spike[i][1].numpy()).replace('[', '').replace(']', '') + '\\n'\n",
    "        f2.write(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
