{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import neuron\n",
    "import linear\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# check gpu\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modify here if you use other datasets\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "input_dimmension = 784                 # input feature의 개수 (MNIST : 784)\n",
    "hidden_dimmension = 100                # hidden layer 개수\n",
    "output_dimmension = 10                 # output label 개수 (MNIST : 10)\n",
    "# if you want to use other dataset\n",
    "#data_path = './WineQT.csv'             # dataset이 저장되어있는 경로 // dataset이 csv파일이고 마지막 feature가 output label이라고 가정\n",
    "\n",
    "\n",
    "# 임의의 dataset을 사용하기 위해 만든 class\n",
    "class SNN_Dataset(Dataset):\n",
    "  def __init__(self, csv_path):\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    self.x_data = df.iloc[:, :-1].values\n",
    "    self.y_data = df.iloc[:, -1].values\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.x_data)\n",
    "  def __getitem__(self, idx):\n",
    "    return self.x_data[idx], self.y_data[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nearly all paramters in this simulation, but it seems no use to store them in a dict...\n",
    "param = {'G_min': -1.0, # the minimum (maximum) value of conductance, I found if I use real conductance value\n",
    "        'G_max': 1.0,   # which is on 1e-4 level, the gradience will be too small even in two layer net.\n",
    "        'Rd': 10e9,    # this device resistance is mannually set for smaller leaky current?\n",
    "        'Cm': 80e-12,   # real capacitance is absolutely larger than this valu\n",
    "        'Rs': 1205000,      # this series resistance value is mannually set for larger inject current?\n",
    "        'Vth': 3.6,     # this is the real device threshould voltage\n",
    "        'V_reset': 3.7,\n",
    "        'dt': 1.75e-4,   # every time step is dt, in the one-order differential equation of neuron\n",
    "        'T_sim': 50,   # could control total spike number collected\n",
    "        'dim_in': input_dimmension,\n",
    "        'dim_h': hidden_dimmension,\n",
    "        'dim_out': output_dimmension,\n",
    "        'amp' : 3,    # the gain of TIAs\n",
    "        'q_bit': 7,    # quantize bit\n",
    "        'epoch': 100,\n",
    "        'batch_size': 2000,\n",
    "        'learning_rate': 0.022,\n",
    "        'data_dir': './MNIST',\n",
    "        'train_file': 'trainning_log_7bit.txt',\n",
    "        'test_file': 'test_log.txt',\n",
    "        'model_dir': 'Model.pth'\n",
    "}\n",
    "\n",
    "def Poisson_encoder(x):\n",
    "    '''\n",
    "    To encode the image pixels to poisson event.\n",
    "\n",
    "    input: a batch of input data x.\n",
    "    output: a batch of poisson encoded 1.0 or 0.0 with the same shape as x,\n",
    "            the possibility of a pixle to be encoded as 1.0 is propotional to the pixel value.\n",
    "    '''\n",
    "    out_spike = torch.rand_like(x).le(x).float()\n",
    "    return out_spike\n",
    "    \n",
    "    \n",
    "class Three_Layer_SNN(nn.Module):\n",
    "    '''\n",
    "    This net model contains 2 linear layer, 2 self-defined BatchNorm layer and 2 Neuron layer.\n",
    "\n",
    "    linear layer: a memristor crossbar on which the MAC operation is implemented.\n",
    "    BatchNorm layer: a row of TIA as the output interface of the pre-linear layer, normalize the\n",
    "                    output current to  -2.0~2.0 V voltage.\n",
    "    neuron layer: nonliear activation, receive input voltage and output spikes, spiking rate is taken\n",
    "                    in loss computing.\n",
    "    '''\n",
    "    def __init__(self, param):\n",
    "        super().__init__()\n",
    "        self.linear1 = linear.MAC_Crossbar(param['dim_in'], param['dim_h'],\n",
    "                                            param['G_min'], param['G_max'], param['q_bit'])\n",
    "        self.BatchNorm1 = linear.TIA_Norm(param['dim_in'], 0.0, 200.0)    # the paramters of TIA are mannually set for moderate input voltage to neurons\n",
    "        self.neuron1 = neuron.LIFNeuron(param['batch_size'], param['dim_h'], param['Rd'], param['Cm'],\n",
    "                                            param['Rs'], param['Vth'], param['V_reset'], param['dt'])\n",
    "        self.linear2 = linear.MAC_Crossbar(param['dim_h'], param['dim_out'],\n",
    "                                            param['G_min'], param['G_max'], param['q_bit'])\n",
    "        self.BatchNorm2 = linear.TIA_Norm(param['dim_h'], 0.0, 200.0)    # same as above\n",
    "        self.neuron2 = neuron.LIFNeuron(param['batch_size'], param['dim_out'], param['Rd'], param['Cm'],\n",
    "                                            param['Rs'], param['Vth'], param['V_reset'], param['dt'])\n",
    "\n",
    "    def forward(self, input_vector):\n",
    "        out_vector = self.linear1(input_vector)\n",
    "        out_vector = self.BatchNorm1(out_vector)\n",
    "\n",
    "        self.neuron1.v = self.neuron1.v.to(device)\n",
    "        self.neuron2.v = self.neuron2.v.to(device)\n",
    "\n",
    "        out_vector = self.neuron1(out_vector)\n",
    "        \n",
    "        out_vector = self.linear2(out_vector)\n",
    "        out_vector = self.BatchNorm2(out_vector)\n",
    "        out_vector = self.neuron2(out_vector)\n",
    "        \n",
    "        return out_vector\n",
    "\n",
    "    def reset_(self):\n",
    "        '''\n",
    "        Reset all neurons after one forward pass,\n",
    "        to ensure the independency of every input image.\n",
    "        '''\n",
    "        for item in self.modules():\n",
    "            if hasattr(item, 'reset'):\n",
    "                item.reset()\n",
    "\n",
    "    def quant_(self):\n",
    "        '''\n",
    "        The quantization function in pytorch only support int8,\n",
    "        so we need our own quant function for adjustable quantization precision.\n",
    "        '''\n",
    "        for item in self.modules():\n",
    "            if hasattr(item, 'Gquant_'):\n",
    "                #debug print：\n",
    "                #print(item.weight.max())\n",
    "                item.Gquant_()\n",
    "                #debug print：\n",
    "                #print(item.weight.max())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tranning epoch 0: the SNN loss is 2.257298 trainning accuracy: 0.1667 validation accuracy: 0.2531\n",
      "elapsed time : 1.4s\n",
      "tranning epoch 1: the SNN loss is 2.209493 trainning accuracy: 0.3732 validation accuracy: 0.4945\n",
      "elapsed time : 2.7s\n",
      "tranning epoch 2: the SNN loss is 2.184917 trainning accuracy: 0.5515 validation accuracy: 0.5955\n",
      "elapsed time : 3.9s\n",
      "tranning epoch 3: the SNN loss is 2.164946 trainning accuracy: 0.6292 validation accuracy: 0.6545\n",
      "elapsed time : 5.1s\n",
      "tranning epoch 4: the SNN loss is 2.154344 trainning accuracy: 0.6691 validation accuracy: 0.6768\n",
      "elapsed time : 6.3s\n",
      "tranning epoch 5: the SNN loss is 2.143142 trainning accuracy: 0.6971 validation accuracy: 0.7123\n",
      "elapsed time : 7.5s\n",
      "tranning epoch 6: the SNN loss is 2.135429 trainning accuracy: 0.7165 validation accuracy: 0.7240\n",
      "elapsed time : 8.8s\n",
      "tranning epoch 7: the SNN loss is 2.131116 trainning accuracy: 0.7334 validation accuracy: 0.7396\n",
      "elapsed time : 10.0s\n",
      "tranning epoch 8: the SNN loss is 2.132857 trainning accuracy: 0.7436 validation accuracy: 0.7500\n",
      "elapsed time : 11.3s\n",
      "tranning epoch 9: the SNN loss is 2.129198 trainning accuracy: 0.7554 validation accuracy: 0.7648\n",
      "elapsed time : 12.6s\n",
      "tranning epoch 10: the SNN loss is 2.122329 trainning accuracy: 0.7605 validation accuracy: 0.7691\n",
      "elapsed time : 13.7s\n",
      "tranning epoch 11: the SNN loss is 2.121375 trainning accuracy: 0.7683 validation accuracy: 0.7806\n",
      "elapsed time : 14.9s\n",
      "tranning epoch 12: the SNN loss is 2.118156 trainning accuracy: 0.7775 validation accuracy: 0.7839\n",
      "elapsed time : 16.1s\n",
      "tranning epoch 13: the SNN loss is 2.113136 trainning accuracy: 0.7800 validation accuracy: 0.7837\n",
      "elapsed time : 17.2s\n",
      "tranning epoch 14: the SNN loss is 2.111109 trainning accuracy: 0.7843 validation accuracy: 0.7952\n",
      "elapsed time : 18.4s\n",
      "tranning epoch 15: the SNN loss is 2.112793 trainning accuracy: 0.7890 validation accuracy: 0.7911\n",
      "elapsed time : 19.6s\n",
      "tranning epoch 16: the SNN loss is 2.109439 trainning accuracy: 0.7981 validation accuracy: 0.7962\n",
      "elapsed time : 20.8s\n",
      "tranning epoch 17: the SNN loss is 2.111137 trainning accuracy: 0.7956 validation accuracy: 0.7981\n",
      "elapsed time : 21.9s\n",
      "tranning epoch 18: the SNN loss is 2.106638 trainning accuracy: 0.7995 validation accuracy: 0.8015\n",
      "elapsed time : 23.1s\n",
      "tranning epoch 19: the SNN loss is 2.103622 trainning accuracy: 0.8013 validation accuracy: 0.8054\n",
      "elapsed time : 24.3s\n",
      "tranning epoch 20: the SNN loss is 2.104994 trainning accuracy: 0.8074 validation accuracy: 0.8083\n",
      "elapsed time : 25.4s\n",
      "tranning epoch 21: the SNN loss is 2.102289 trainning accuracy: 0.8075 validation accuracy: 0.8150\n",
      "elapsed time : 26.6s\n",
      "tranning epoch 22: the SNN loss is 2.103545 trainning accuracy: 0.8081 validation accuracy: 0.8105\n",
      "elapsed time : 27.8s\n",
      "tranning epoch 23: the SNN loss is 2.099955 trainning accuracy: 0.8122 validation accuracy: 0.8147\n",
      "elapsed time : 28.9s\n",
      "tranning epoch 24: the SNN loss is 2.102736 trainning accuracy: 0.8133 validation accuracy: 0.8118\n",
      "elapsed time : 30.2s\n",
      "tranning epoch 25: the SNN loss is 2.099590 trainning accuracy: 0.8161 validation accuracy: 0.8194\n",
      "elapsed time : 31.6s\n",
      "tranning epoch 26: the SNN loss is 2.099795 trainning accuracy: 0.8161 validation accuracy: 0.8141\n",
      "elapsed time : 32.8s\n",
      "tranning epoch 27: the SNN loss is 2.099045 trainning accuracy: 0.8187 validation accuracy: 0.8178\n",
      "elapsed time : 34.1s\n",
      "tranning epoch 28: the SNN loss is 2.099650 trainning accuracy: 0.8209 validation accuracy: 0.8261\n",
      "elapsed time : 35.3s\n",
      "tranning epoch 29: the SNN loss is 2.093781 trainning accuracy: 0.8228 validation accuracy: 0.8204\n",
      "elapsed time : 36.6s\n",
      "tranning epoch 30: the SNN loss is 2.095908 trainning accuracy: 0.8216 validation accuracy: 0.8212\n",
      "elapsed time : 37.9s\n",
      "tranning epoch 31: the SNN loss is 2.097146 trainning accuracy: 0.8239 validation accuracy: 0.8214\n",
      "elapsed time : 39.2s\n",
      "tranning epoch 32: the SNN loss is 2.094628 trainning accuracy: 0.8235 validation accuracy: 0.8288\n",
      "elapsed time : 40.4s\n",
      "tranning epoch 33: the SNN loss is 2.095387 trainning accuracy: 0.8262 validation accuracy: 0.8262\n",
      "elapsed time : 41.7s\n",
      "tranning epoch 34: the SNN loss is 2.095393 trainning accuracy: 0.8268 validation accuracy: 0.8256\n",
      "elapsed time : 43.0s\n",
      "tranning epoch 35: the SNN loss is 2.097343 trainning accuracy: 0.8288 validation accuracy: 0.8287\n",
      "elapsed time : 44.1s\n",
      "tranning epoch 36: the SNN loss is 2.094305 trainning accuracy: 0.8286 validation accuracy: 0.8293\n",
      "elapsed time : 45.3s\n",
      "tranning epoch 37: the SNN loss is 2.094415 trainning accuracy: 0.8270 validation accuracy: 0.8293\n",
      "elapsed time : 46.6s\n",
      "tranning epoch 38: the SNN loss is 2.095484 trainning accuracy: 0.8296 validation accuracy: 0.8308\n",
      "elapsed time : 47.9s\n",
      "tranning epoch 39: the SNN loss is 2.093306 trainning accuracy: 0.8306 validation accuracy: 0.8278\n",
      "elapsed time : 49.2s\n",
      "tranning epoch 40: the SNN loss is 2.093592 trainning accuracy: 0.8290 validation accuracy: 0.8322\n",
      "elapsed time : 50.4s\n",
      "tranning epoch 41: the SNN loss is 2.091632 trainning accuracy: 0.8315 validation accuracy: 0.8332\n",
      "elapsed time : 51.7s\n",
      "tranning epoch 42: the SNN loss is 2.092699 trainning accuracy: 0.8328 validation accuracy: 0.8247\n",
      "elapsed time : 53.0s\n",
      "tranning epoch 43: the SNN loss is 2.091776 trainning accuracy: 0.8331 validation accuracy: 0.8307\n",
      "elapsed time : 54.2s\n",
      "tranning epoch 44: the SNN loss is 2.088934 trainning accuracy: 0.8320 validation accuracy: 0.8312\n",
      "elapsed time : 55.5s\n",
      "tranning epoch 45: the SNN loss is 2.091198 trainning accuracy: 0.8332 validation accuracy: 0.8377\n",
      "elapsed time : 56.8s\n",
      "tranning epoch 46: the SNN loss is 2.089326 trainning accuracy: 0.8350 validation accuracy: 0.8339\n",
      "elapsed time : 58.0s\n",
      "tranning epoch 47: the SNN loss is 2.090976 trainning accuracy: 0.8360 validation accuracy: 0.8323\n",
      "elapsed time : 59.3s\n",
      "tranning epoch 48: the SNN loss is 2.087251 trainning accuracy: 0.8341 validation accuracy: 0.8310\n",
      "elapsed time : 60.6s\n",
      "tranning epoch 49: the SNN loss is 2.088202 trainning accuracy: 0.8354 validation accuracy: 0.8390\n",
      "elapsed time : 61.8s\n",
      "tranning epoch 50: the SNN loss is 2.085788 trainning accuracy: 0.8345 validation accuracy: 0.8369\n",
      "elapsed time : 63.0s\n",
      "tranning epoch 51: the SNN loss is 2.089085 trainning accuracy: 0.8343 validation accuracy: 0.8363\n",
      "elapsed time : 64.2s\n",
      "tranning epoch 52: the SNN loss is 2.088444 trainning accuracy: 0.8344 validation accuracy: 0.8346\n",
      "elapsed time : 65.4s\n",
      "tranning epoch 53: the SNN loss is 2.089039 trainning accuracy: 0.8365 validation accuracy: 0.8380\n",
      "elapsed time : 66.6s\n",
      "tranning epoch 54: the SNN loss is 2.087996 trainning accuracy: 0.8375 validation accuracy: 0.8355\n",
      "elapsed time : 67.8s\n",
      "tranning epoch 55: the SNN loss is 2.088321 trainning accuracy: 0.8394 validation accuracy: 0.8363\n",
      "elapsed time : 69.0s\n",
      "tranning epoch 56: the SNN loss is 2.083420 trainning accuracy: 0.8405 validation accuracy: 0.8352\n",
      "elapsed time : 70.3s\n",
      "tranning epoch 57: the SNN loss is 2.087724 trainning accuracy: 0.8397 validation accuracy: 0.8358\n",
      "elapsed time : 71.5s\n",
      "tranning epoch 58: the SNN loss is 2.091115 trainning accuracy: 0.8393 validation accuracy: 0.8336\n",
      "elapsed time : 72.7s\n",
      "tranning epoch 59: the SNN loss is 2.084714 trainning accuracy: 0.8405 validation accuracy: 0.8370\n",
      "elapsed time : 73.9s\n",
      "tranning epoch 60: the SNN loss is 2.088541 trainning accuracy: 0.8394 validation accuracy: 0.8361\n",
      "elapsed time : 75.1s\n",
      "tranning epoch 61: the SNN loss is 2.087601 trainning accuracy: 0.8408 validation accuracy: 0.8387\n",
      "elapsed time : 76.3s\n",
      "tranning epoch 62: the SNN loss is 2.083035 trainning accuracy: 0.8419 validation accuracy: 0.8425\n",
      "elapsed time : 77.5s\n",
      "tranning epoch 63: the SNN loss is 2.084736 trainning accuracy: 0.8406 validation accuracy: 0.8410\n",
      "elapsed time : 78.8s\n",
      "tranning epoch 64: the SNN loss is 2.086863 trainning accuracy: 0.8411 validation accuracy: 0.8422\n",
      "elapsed time : 79.9s\n",
      "tranning epoch 65: the SNN loss is 2.086532 trainning accuracy: 0.8426 validation accuracy: 0.8454\n",
      "elapsed time : 81.1s\n",
      "tranning epoch 66: the SNN loss is 2.084245 trainning accuracy: 0.8434 validation accuracy: 0.8471\n",
      "elapsed time : 82.3s\n",
      "tranning epoch 67: the SNN loss is 2.086369 trainning accuracy: 0.8423 validation accuracy: 0.8391\n",
      "elapsed time : 83.6s\n",
      "tranning epoch 68: the SNN loss is 2.086635 trainning accuracy: 0.8423 validation accuracy: 0.8352\n",
      "elapsed time : 84.8s\n",
      "tranning epoch 69: the SNN loss is 2.085629 trainning accuracy: 0.8414 validation accuracy: 0.8408\n",
      "elapsed time : 86.1s\n",
      "tranning epoch 70: the SNN loss is 2.087882 trainning accuracy: 0.8410 validation accuracy: 0.8359\n",
      "elapsed time : 87.3s\n",
      "tranning epoch 71: the SNN loss is 2.086500 trainning accuracy: 0.8409 validation accuracy: 0.8402\n",
      "elapsed time : 88.4s\n",
      "tranning epoch 72: the SNN loss is 2.083943 trainning accuracy: 0.8417 validation accuracy: 0.8426\n",
      "elapsed time : 89.6s\n",
      "tranning epoch 73: the SNN loss is 2.084783 trainning accuracy: 0.8429 validation accuracy: 0.8416\n",
      "elapsed time : 90.9s\n",
      "tranning epoch 74: the SNN loss is 2.084754 trainning accuracy: 0.8417 validation accuracy: 0.8373\n",
      "elapsed time : 92.1s\n",
      "tranning epoch 75: the SNN loss is 2.086779 trainning accuracy: 0.8427 validation accuracy: 0.8394\n",
      "elapsed time : 93.3s\n",
      "tranning epoch 76: the SNN loss is 2.088445 trainning accuracy: 0.8436 validation accuracy: 0.8439\n",
      "elapsed time : 94.6s\n",
      "tranning epoch 77: the SNN loss is 2.087363 trainning accuracy: 0.8431 validation accuracy: 0.8392\n",
      "elapsed time : 95.9s\n",
      "tranning epoch 78: the SNN loss is 2.084658 trainning accuracy: 0.8441 validation accuracy: 0.8425\n",
      "elapsed time : 97.3s\n",
      "tranning epoch 79: the SNN loss is 2.085821 trainning accuracy: 0.8436 validation accuracy: 0.8433\n",
      "elapsed time : 98.5s\n",
      "tranning epoch 80: the SNN loss is 2.085093 trainning accuracy: 0.8437 validation accuracy: 0.8446\n",
      "elapsed time : 99.8s\n",
      "tranning epoch 81: the SNN loss is 2.084421 trainning accuracy: 0.8434 validation accuracy: 0.8403\n",
      "elapsed time : 101.0s\n",
      "tranning epoch 82: the SNN loss is 2.086571 trainning accuracy: 0.8443 validation accuracy: 0.8421\n",
      "elapsed time : 102.2s\n",
      "tranning epoch 83: the SNN loss is 2.081321 trainning accuracy: 0.8442 validation accuracy: 0.8410\n",
      "elapsed time : 103.4s\n",
      "tranning epoch 84: the SNN loss is 2.085310 trainning accuracy: 0.8462 validation accuracy: 0.8428\n",
      "elapsed time : 104.5s\n",
      "tranning epoch 85: the SNN loss is 2.085173 trainning accuracy: 0.8441 validation accuracy: 0.8403\n",
      "elapsed time : 105.7s\n",
      "tranning epoch 86: the SNN loss is 2.083382 trainning accuracy: 0.8457 validation accuracy: 0.8429\n",
      "elapsed time : 106.8s\n",
      "tranning epoch 87: the SNN loss is 2.081441 trainning accuracy: 0.8456 validation accuracy: 0.8473\n",
      "elapsed time : 108.0s\n",
      "tranning epoch 88: the SNN loss is 2.080813 trainning accuracy: 0.8453 validation accuracy: 0.8436\n",
      "elapsed time : 109.2s\n",
      "tranning epoch 89: the SNN loss is 2.085191 trainning accuracy: 0.8472 validation accuracy: 0.8411\n",
      "elapsed time : 110.4s\n",
      "tranning epoch 90: the SNN loss is 2.089256 trainning accuracy: 0.8464 validation accuracy: 0.8415\n",
      "elapsed time : 111.6s\n",
      "tranning epoch 91: the SNN loss is 2.085727 trainning accuracy: 0.8441 validation accuracy: 0.8470\n",
      "elapsed time : 112.8s\n",
      "tranning epoch 92: the SNN loss is 2.083194 trainning accuracy: 0.8446 validation accuracy: 0.8431\n",
      "elapsed time : 114.0s\n",
      "tranning epoch 93: the SNN loss is 2.084790 trainning accuracy: 0.8455 validation accuracy: 0.8425\n",
      "elapsed time : 115.4s\n",
      "tranning epoch 94: the SNN loss is 2.084725 trainning accuracy: 0.8469 validation accuracy: 0.8422\n",
      "elapsed time : 116.7s\n",
      "tranning epoch 95: the SNN loss is 2.081016 trainning accuracy: 0.8448 validation accuracy: 0.8482\n",
      "elapsed time : 117.9s\n",
      "tranning epoch 96: the SNN loss is 2.083574 trainning accuracy: 0.8469 validation accuracy: 0.8439\n",
      "elapsed time : 119.1s\n",
      "tranning epoch 97: the SNN loss is 2.082785 trainning accuracy: 0.8465 validation accuracy: 0.8421\n",
      "elapsed time : 120.3s\n",
      "tranning epoch 98: the SNN loss is 2.086353 trainning accuracy: 0.8462 validation accuracy: 0.8461\n",
      "elapsed time : 121.5s\n",
      "tranning epoch 99: the SNN loss is 2.085554 trainning accuracy: 0.8464 validation accuracy: 0.8498\n",
      "elapsed time : 122.8s\n"
     ]
    }
   ],
   "source": [
    "# Poisson Encoding\n",
    "\n",
    "trainset = torchvision.datasets.MNIST(root=param['data_dir'], train=True,\n",
    "                                        download=True, transform=transforms.ToTensor())\n",
    "testset = torchvision.datasets.MNIST(root=param['data_dir'], train=False,\n",
    "                                        download=True, transform=transforms.ToTensor())\n",
    "trainloader = torch.utils.data.DataLoader(dataset=trainset, batch_size=param['batch_size'],\n",
    "                                            shuffle=True, drop_last=True, num_workers=2, pin_memory=True)\n",
    "testloader = torch.utils.data.DataLoader(dataset=testset, batch_size=param['batch_size'],\n",
    "                                            shuffle=False, drop_last=True, num_workers=2, pin_memory=True)\n",
    "\n",
    "#Train the SNN with BP\n",
    "net = Three_Layer_SNN(param).to(device)\n",
    "loss_func = torch.nn.CrossEntropyLoss().to(device)\n",
    "optim = torch.optim.Adam(net.parameters(), param['learning_rate'])\n",
    "\n",
    "start = time.time()\n",
    "for epoch in range(param['epoch']):\n",
    "    net.train()\n",
    "    train_accuracy = []\n",
    "    \n",
    "    for img, label in trainloader:\n",
    "        img = img.reshape(-1, input_dimmension)\n",
    "        # using gpu\n",
    "        img, label = img.to(device), label.to(device)\n",
    "        spike_num_img = torch.zeros(param['batch_size'], param['dim_out']).to(device)\n",
    "\n",
    "        net.reset_()\n",
    "        for t in range(param['T_sim']):\n",
    "            new_img = Poisson_encoder(img)\n",
    "            out_spike = net(new_img)\n",
    "            spike_num_img += out_spike\n",
    "\n",
    "        spike_rate = spike_num_img/param['T_sim']\n",
    "        loss = loss_func(spike_rate, label)\n",
    "\n",
    "        #net.zero_grad()\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            net.reset_()    # reset the neuron voltage every batch, to ensure independency between batchs\n",
    "            net.quant_()    # quantize the weights after weight update\n",
    "\n",
    "        train_accuracy.append((spike_rate.max(1)[1] == label).float().mean().item())\n",
    "    accuracy_epoch = np.mean(train_accuracy)\n",
    "    print('tranning epoch %d: the SNN loss is %.6f' %(epoch, loss), end=' ')\n",
    "    print('trainning accuracy: %.4f' %accuracy_epoch, end=' ')\n",
    "    \n",
    "# validation by testset every epoch to see if the network is overfitted\n",
    "    net.eval()\n",
    "    validation_accuracy = []\n",
    "    with torch.no_grad():\n",
    "        for img_test, label_test in testloader:\n",
    "            img_test = img_test.reshape(-1, input_dimmension)\n",
    "            \n",
    "            # using gpu\n",
    "            spike_num_img_test = torch.zeros(param['batch_size'], param['dim_out']).to(device)\n",
    "            img_test, label_test = img_test.to(device), label_test.to(device)\n",
    "\n",
    "            net.reset_() #set the neuron voltage as reset voltage\n",
    "            for t in range(param['T_sim']):\n",
    "                new_img = Poisson_encoder(img_test)\n",
    "                out_spike = net(new_img)\n",
    "                spike_num_img_test += out_spike \n",
    "                \n",
    "            validation_accuracy.append((spike_num_img_test.max(1)[1]==label_test).float().mean().item())\n",
    "        accuracy_val = np.mean(validation_accuracy)\n",
    "        print('validation accuracy: %.4f' %accuracy_val)\n",
    "        print('elapsed time : {0:.1f}s' .format(time.time() - start))\n",
    "\n",
    "    with open(param['train_file'], 'a') as f_t:\n",
    "        s = str(epoch).ljust(6, ' ') + str(round(loss.item(), 6)).ljust(12, ' ')\n",
    "        s += str(round(accuracy_epoch, 4)).ljust(10, ' ') + str(round(accuracy_val, 4)).ljust(10, ' ')\n",
    "        f_t.write(s)\n",
    "\n",
    "torch.save(net.state_dict(), param['model_dir'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Model, please wait......\n",
      "Model loaded successfully!\n",
      "Test Accuracy: 83.91%\n"
     ]
    }
   ],
   "source": [
    "# Test process after training\n",
    "net_test = Three_Layer_SNN(param).to(device)\n",
    "print('Loading Model, please wait......')\n",
    "net_test.load_state_dict(torch.load(param['model_dir'], weights_only=True))\n",
    "print('Model loaded successfully!')\n",
    "list_num_spike = []\n",
    "for i in range(10):\n",
    "    list_num_spike.append([0])\n",
    "    list_num_spike[i].append(torch.zeros(param['dim_out']))\n",
    "\n",
    "total_correct = 0  # 전체 맞춘 예측 수\n",
    "total_samples = 0  # 전체 테스트 샘플 수\n",
    "\n",
    "with torch.no_grad():\n",
    "    for img_test, label_test in testloader:\n",
    "        img_test = img_test.reshape(-1, 28 * 28)\n",
    "        spike_num_img_test = torch.zeros(param['batch_size'], param['dim_out']).to(device)\n",
    "        net_test.reset_()  # set the neuron voltage as reset voltage\n",
    "\n",
    "        # using gpu\n",
    "        img_test, label_test = img_test.to(device), label_test.to(device)\n",
    "\n",
    "        net.reset_()  # set the neuron voltage as reset voltage\n",
    "\n",
    "        for t in range(param['T_sim']):\n",
    "            new_test_img = Poisson_encoder(img_test)\n",
    "            out_spike = net_test(new_test_img)\n",
    "            spike_num_img_test += out_spike\n",
    "            # update mask\n",
    "\n",
    "        pred_label = F.one_hot(spike_num_img_test.max(1)[1], num_classes=10).to('cpu')  # convert the max neuron output index to onehot vector\n",
    "\n",
    "        # Accuracy calculation\n",
    "        pred_label_class = spike_num_img_test.max(1)[1]  # predicted class for each image in the batch\n",
    "        total_correct += (pred_label_class == label_test).sum().item()  # count correct predictions\n",
    "        total_samples += label_test.size(0)  # update total samples\n",
    "\n",
    "        for j in range(label_test.size(0)):\n",
    "            index = label_test[j]\n",
    "            list_num_spike[index][0] += 1\n",
    "            list_num_spike[index][1] += pred_label[j].to('cpu')  # statistics of prediction for every input image\n",
    "\n",
    "# Calculate and print overall accuracy\n",
    "accuracy = total_correct / total_samples * 100\n",
    "print(f'Test Accuracy: {accuracy:.2f}%')\n",
    "\n",
    "# Save confusion matrix\n",
    "with open('confusion_matrix.txt', 'a') as f2:\n",
    "    for i in range(len(list_num_spike)):\n",
    "        s = str(list_num_spike[i][0]) + ' ' + str(list_num_spike[i][1].numpy()).replace('[', '').replace(']', '') + '\\n'\n",
    "        f2.write(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
