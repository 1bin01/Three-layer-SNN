{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import neuron\n",
    "import linear\n",
    "import time\n",
    "# library from snntorch\n",
    "from ttfe import latency "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# check gpu\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modify here if you use other datasets\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "input_dimmension = 784                 # input feature의 개수 (MNIST : 784)\n",
    "hidden_dimmension = 100                # hidden layer 개수\n",
    "output_dimmension = 10                 # output label 개수 (MNIST : 10)\n",
    "batch_sz = 128                         # batch size : dataset의 크기에 따라 조절 \n",
    "# if you want to use other dataset\n",
    "#data_path = './WineQT.csv'             # dataset이 저장되어있는 경로 // dataset이 csv파일이고 마지막 feature가 output label이라고 가정\n",
    "\n",
    "\n",
    "# 임의의 dataset을 사용하기 위해 만든 class\n",
    "class SNN_Dataset(Dataset):\n",
    "  def __init__(self, csv_path):\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    self.x_data = df.iloc[:, :-1].values\n",
    "    self.y_data = df.iloc[:, -1].values\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.x_data)\n",
    "  def __getitem__(self, idx):\n",
    "    return self.x_data[idx], self.y_data[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nearly all paramters in this simulation, but it seems no use to store them in a dict...\n",
    "param = {'G_min': -1.0, # the minimum (maximum) value of conductance, I found if I use real conductance value,#-1.0\n",
    "        'G_max': 1.0,   # which is on 1e-4 level, the gradience will be too small even in two layer net.#1.0\n",
    "        'Rd': 10e9,    # this device resistance is mannually set for smaller leaky current? / 5.0e9\n",
    "        'Cm': 80e-12,   # real capacitance is absolutely larger than this value / 0.8e-10\n",
    "        'Rs': 1005000,      # this series resistance value is mannually set for larger inject current?\n",
    "        'Vth': 4.2,     # this is the real device threshould voltage #5.6\n",
    "        'V_reset': 3.7,\n",
    "        'dt': 1.75e-4,   # every time step is dt, in the one-order differential equation of neuron\n",
    "        'T_sim': 20,   # could control total spike number collected\n",
    "        'dim_in': input_dimmension,\n",
    "        'dim_h': hidden_dimmension,\n",
    "        'dim_out': output_dimmension,\n",
    "        'amp' : 3,    # the gain of TIAs\n",
    "        'q_bit': 7,    # quantize bit\n",
    "        'epoch': 100,\n",
    "        'batch_size': batch_sz,\n",
    "        'learning_rate': 0.015,\n",
    "        'data_dir': './MNIST',\n",
    "        'train_file': 'trainning_log_7bit.txt',\n",
    "        'test_file': 'test_log.txt',\n",
    "        'model_dir': 'Model.pth'\n",
    "}\n",
    "\n",
    "def rate_encoding(x, T_sim):\n",
    "    '''\n",
    "    Encodes the input image pixels into periodic spike trains.\n",
    "    \n",
    "    input : x (batch_size, dim_in) - input data\n",
    "           T_sim (int) - number of time steps for the simulation\n",
    "    output : (batch_size, dim_in, T_sim) - periodic spikes for each pixel over T_sim time steps\n",
    "    '''\n",
    "    \n",
    "    batch_size, dim_in = x.shape\n",
    "    spikes = torch.zeros(batch_size, dim_in, T_sim).to(x.device)  # Initialize spikes tensor\n",
    "\n",
    "    # Data directly obtained through research\n",
    "    pixel_values = torch.tensor([0, 0.287273, 0.389091, 0.592727, 0.796364, 1]).to(x.device)\n",
    "    periods = torch.tensor([6.5, 3.1, 2.6, 2.2, 1.9, 1.7]).to(x.device)\n",
    "    \n",
    "    period = torch.zeros_like(x)\n",
    "    for i in range(len(pixel_values) - 1):\n",
    "        mask = (x >= pixel_values[i]) & (x < pixel_values[i+1])\n",
    "        # Linearly interpolate periods for those pixels\n",
    "        period[mask] = periods[i] + (periods[i+1] - periods[i]) * (x[mask] - pixel_values[i]) / (pixel_values[i+1] - pixel_values[i])\n",
    "    period[x == 1] = 1.7\n",
    "\n",
    "    for t in range(T_sim):\n",
    "        spikes[:, :, t] = ((t+1) // period > t // period)\n",
    "    return spikes\n",
    "\n",
    "\n",
    "def ttfs_encoding(x, T_sim):\n",
    "    '''\n",
    "    Encodes the input image pixels using time-to-first-spike encoding based on provided data.\n",
    "\n",
    "    input: x (batch_size, dim_in) - input data\n",
    "           T_sim (int) - number of time steps for the simulation\n",
    "    output: (batch_size, dim_in, T_sim) - time-to-first-spike encoded spikes\n",
    "    '''\n",
    "    \n",
    "    batch_size, dim_in = x.shape\n",
    "    spikes = torch.zeros(batch_size, dim_in, T_sim).to(x.device)\n",
    "\n",
    "    # Data directly obtained through research\n",
    "    pixel_values = torch.tensor([0, 0.287273, 0.389091, 0.592727, 0.796364, 1]).to(x.device)\n",
    "    spike_times = torch.tensor([14.3, 12.4, 11.8, 11.4, 11.3, 11.2]).to(x.device) \n",
    "    \n",
    "    spike_times = spike_times - 11.2  # starts after 11.2ms for efficient model training\n",
    "    spike_time = torch.zeros_like(x)\n",
    "    \n",
    "    for i in range(len(pixel_values) - 1):\n",
    "        mask = (x >= pixel_values[i]) & (x < pixel_values[i+1])\n",
    "        # Linearly interpolate spike times based on pixel values\n",
    "        spike_time[mask] = spike_times[i] + (spike_times[i+1] - spike_times[i]) * (x[mask] - pixel_values[i]) / (pixel_values[i+1] - pixel_values[i])\n",
    "    spike_time[x == 1] = spike_times[-1]\n",
    "    \n",
    "    for t in range(T_sim):\n",
    "        spikes[:, :, t] = (spike_time < t + 1).float() * (spike_time >= t).float()\n",
    "    return spikes\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "class Three_Layer_SNN(nn.Module):\n",
    "    '''\n",
    "    This net model contains 2 linear layer, 2 self-defined BatchNorm layer and 2 Neuron layer.\n",
    "\n",
    "    linear layer: a memristor crossbar on which the MAC operation is implemented.\n",
    "    BatchNorm layer: a row of TIA as the output interface of the pre-linear layer, normalize the\n",
    "                    output current to  -2.0~2.0 V voltage.\n",
    "    neuron layer: nonliear activation, receive input voltage and output spikes, spiking rate is taken\n",
    "                    in loss computing.\n",
    "    '''\n",
    "    def __init__(self, param):\n",
    "        super().__init__()\n",
    "        self.linear1 = linear.MAC_Crossbar(param['dim_in'], param['dim_h'],\n",
    "                                            param['G_min'], param['G_max'], param['q_bit'])\n",
    "        self.BatchNorm1 = linear.TIA_Norm(param['dim_in'], 0.0, 200.0)    # the paramters of TIA are mannually set for moderate input voltage to neurons\n",
    "        self.neuron1 = neuron.LIFNeuron(param['batch_size'], param['dim_h'], param['Rd'], param['Cm'],\n",
    "                                            param['Rs'], param['Vth'], param['V_reset'], param['dt'])\n",
    "        self.linear2 = linear.MAC_Crossbar(param['dim_h'], param['dim_out'],\n",
    "                                            param['G_min'], param['G_max'], param['q_bit'])\n",
    "        self.BatchNorm2 = linear.TIA_Norm(param['dim_h'], 0.0, 200.0)    # same as above\n",
    "        self.neuron2 = neuron.LIFNeuron(param['batch_size'], param['dim_out'], param['Rd'], param['Cm'],\n",
    "                                            param['Rs'], param['Vth'], param['V_reset'], param['dt'])\n",
    "\n",
    "    def forward(self, input_vector):\n",
    "        total_spikes = 0 # total spike count\n",
    "        \n",
    "        out_vector = self.linear1(input_vector)\n",
    "        out_vector = self.BatchNorm1(out_vector)\n",
    "\n",
    "        self.neuron1.v = self.neuron1.v.to(device)\n",
    "        self.neuron2.v = self.neuron2.v.to(device)\n",
    "\n",
    "        out_vector = self.neuron1(out_vector)\n",
    "        total_spikes += torch.sum(out_vector == 1).item()\n",
    "        \n",
    "        out_vector = self.linear2(out_vector)\n",
    "        out_vector = self.BatchNorm2(out_vector)\n",
    "        out_vector = self.neuron2(out_vector)\n",
    "        total_spikes += torch.sum(out_vector == 1).item()\n",
    "        \n",
    "        return out_vector, total_spikes\n",
    "\n",
    "    def reset_(self):\n",
    "        '''\n",
    "        Reset all neurons after one forward pass,\n",
    "        to ensure the independency of every input image.\n",
    "        '''\n",
    "        for item in self.modules():\n",
    "            if hasattr(item, 'reset'):\n",
    "                item.reset()\n",
    "\n",
    "    def quant_(self):\n",
    "        '''\n",
    "        The quantization function in pytorch only support int8,\n",
    "        so we need our own quant function for adjustable quantization precision.\n",
    "        '''\n",
    "        for item in self.modules():\n",
    "            if hasattr(item, 'Gquant_'):\n",
    "                #debug print：\n",
    "                #print(item.weight.max())\n",
    "                item.Gquant_()\n",
    "                #debug print：\n",
    "                #print(item.weight.max())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pixel Values: tensor([[0.0000, 0.0101, 0.0202, 0.0303, 0.0404, 0.0505, 0.0606, 0.0707, 0.0808,\n",
      "         0.0909, 0.1010, 0.1111, 0.1212, 0.1313, 0.1414, 0.1515, 0.1616, 0.1717,\n",
      "         0.1818, 0.1919, 0.2020, 0.2121, 0.2222, 0.2323, 0.2424, 0.2525, 0.2626,\n",
      "         0.2727, 0.2828, 0.2929, 0.3030, 0.3131, 0.3232, 0.3333, 0.3434, 0.3535,\n",
      "         0.3636, 0.3737, 0.3838, 0.3939, 0.4040, 0.4141, 0.4242, 0.4343, 0.4444,\n",
      "         0.4545, 0.4646, 0.4747, 0.4848, 0.4949, 0.5051, 0.5152, 0.5253, 0.5354,\n",
      "         0.5455, 0.5556, 0.5657, 0.5758, 0.5859, 0.5960, 0.6061, 0.6162, 0.6263,\n",
      "         0.6364, 0.6465, 0.6566, 0.6667, 0.6768, 0.6869, 0.6970, 0.7071, 0.7172,\n",
      "         0.7273, 0.7374, 0.7475, 0.7576, 0.7677, 0.7778, 0.7879, 0.7980, 0.8081,\n",
      "         0.8182, 0.8283, 0.8384, 0.8485, 0.8586, 0.8687, 0.8788, 0.8889, 0.8990,\n",
      "         0.9091, 0.9192, 0.9293, 0.9394, 0.9495, 0.9596, 0.9697, 0.9798, 0.9899,\n",
      "         1.0000]])\n",
      "\n",
      " ttfe spike time with snntorch :\n",
      "Pixel 0.0: Spikes at time step(s) []\n",
      "Pixel 0.010101010091602802: Spikes at time step(s) []\n",
      "Pixel 0.020202020183205605: Spikes at time step(s) [7]\n",
      "Pixel 0.03030303120613098: Spikes at time step(s) [4]\n",
      "Pixel 0.04040404036641121: Spikes at time step(s) [3]\n",
      "Pixel 0.05050504952669144: Spikes at time step(s) [2]\n",
      "Pixel 0.06060606241226196: Spikes at time step(s) [2]\n",
      "Pixel 0.07070706784725189: Spikes at time step(s) [2]\n",
      "Pixel 0.08080808073282242: Spikes at time step(s) [1]\n",
      "Pixel 0.09090909361839294: Spikes at time step(s) [1]\n",
      "Pixel 0.10101009905338287: Spikes at time step(s) [1]\n",
      "Pixel 0.1111111119389534: Spikes at time step(s) [1]\n",
      "Pixel 0.12121212482452393: Spikes at time step(s) [1]\n",
      "Pixel 0.13131313025951385: Spikes at time step(s) [1]\n",
      "Pixel 0.14141413569450378: Spikes at time step(s) [1]\n",
      "Pixel 0.1515151560306549: Spikes at time step(s) [1]\n",
      "Pixel 0.16161616146564484: Spikes at time step(s) [1]\n",
      "Pixel 0.17171716690063477: Spikes at time step(s) [1]\n",
      "Pixel 0.1818181872367859: Spikes at time step(s) [1]\n",
      "Pixel 0.19191919267177582: Spikes at time step(s) [1]\n",
      "Pixel 0.20202019810676575: Spikes at time step(s) [1]\n",
      "Pixel 0.21212121844291687: Spikes at time step(s) [0]\n",
      "Pixel 0.2222222238779068: Spikes at time step(s) [0]\n",
      "Pixel 0.23232322931289673: Spikes at time step(s) [0]\n",
      "Pixel 0.24242424964904785: Spikes at time step(s) [0]\n",
      "Pixel 0.2525252401828766: Spikes at time step(s) [0]\n",
      "Pixel 0.2626262605190277: Spikes at time step(s) [0]\n",
      "Pixel 0.27272728085517883: Spikes at time step(s) [0]\n",
      "Pixel 0.28282827138900757: Spikes at time step(s) [0]\n",
      "Pixel 0.2929292917251587: Spikes at time step(s) [0]\n",
      "Pixel 0.3030303120613098: Spikes at time step(s) [0]\n",
      "Pixel 0.31313130259513855: Spikes at time step(s) [0]\n",
      "Pixel 0.3232323229312897: Spikes at time step(s) [0]\n",
      "Pixel 0.3333333432674408: Spikes at time step(s) [0]\n",
      "Pixel 0.34343433380126953: Spikes at time step(s) [0]\n",
      "Pixel 0.35353535413742065: Spikes at time step(s) [0]\n",
      "Pixel 0.3636363744735718: Spikes at time step(s) [0]\n",
      "Pixel 0.3737373650074005: Spikes at time step(s) [0]\n",
      "Pixel 0.38383838534355164: Spikes at time step(s) [0]\n",
      "Pixel 0.39393940567970276: Spikes at time step(s) [0]\n",
      "Pixel 0.4040403962135315: Spikes at time step(s) [0]\n",
      "Pixel 0.4141414165496826: Spikes at time step(s) [0]\n",
      "Pixel 0.42424243688583374: Spikes at time step(s) [0]\n",
      "Pixel 0.4343434274196625: Spikes at time step(s) [0]\n",
      "Pixel 0.4444444477558136: Spikes at time step(s) [0]\n",
      "Pixel 0.4545454680919647: Spikes at time step(s) [0]\n",
      "Pixel 0.46464645862579346: Spikes at time step(s) [0]\n",
      "Pixel 0.4747474789619446: Spikes at time step(s) [0]\n",
      "Pixel 0.4848484992980957: Spikes at time step(s) [0]\n",
      "Pixel 0.49494948983192444: Spikes at time step(s) [0]\n",
      "Pixel 0.5050504803657532: Spikes at time step(s) [0]\n",
      "Pixel 0.5151515007019043: Spikes at time step(s) [0]\n",
      "Pixel 0.5252525210380554: Spikes at time step(s) [0]\n",
      "Pixel 0.5353535413742065: Spikes at time step(s) [0]\n",
      "Pixel 0.5454545617103577: Spikes at time step(s) [0]\n",
      "Pixel 0.5555555820465088: Spikes at time step(s) [0]\n",
      "Pixel 0.5656565427780151: Spikes at time step(s) [0]\n",
      "Pixel 0.5757575631141663: Spikes at time step(s) [0]\n",
      "Pixel 0.5858585834503174: Spikes at time step(s) [0]\n",
      "Pixel 0.5959596037864685: Spikes at time step(s) [0]\n",
      "Pixel 0.6060606241226196: Spikes at time step(s) [0]\n",
      "Pixel 0.6161616444587708: Spikes at time step(s) [0]\n",
      "Pixel 0.6262626051902771: Spikes at time step(s) [0]\n",
      "Pixel 0.6363636255264282: Spikes at time step(s) [0]\n",
      "Pixel 0.6464646458625793: Spikes at time step(s) [0]\n",
      "Pixel 0.6565656661987305: Spikes at time step(s) [0]\n",
      "Pixel 0.6666666865348816: Spikes at time step(s) [0]\n",
      "Pixel 0.6767677068710327: Spikes at time step(s) [0]\n",
      "Pixel 0.6868686676025391: Spikes at time step(s) [0]\n",
      "Pixel 0.6969696879386902: Spikes at time step(s) [0]\n",
      "Pixel 0.7070707082748413: Spikes at time step(s) [0]\n",
      "Pixel 0.7171717286109924: Spikes at time step(s) [0]\n",
      "Pixel 0.7272727489471436: Spikes at time step(s) [0]\n",
      "Pixel 0.7373737096786499: Spikes at time step(s) [0]\n",
      "Pixel 0.747474730014801: Spikes at time step(s) [0]\n",
      "Pixel 0.7575757503509521: Spikes at time step(s) [0]\n",
      "Pixel 0.7676767706871033: Spikes at time step(s) [0]\n",
      "Pixel 0.7777777910232544: Spikes at time step(s) [0]\n",
      "Pixel 0.7878788113594055: Spikes at time step(s) [0]\n",
      "Pixel 0.7979797720909119: Spikes at time step(s) [0]\n",
      "Pixel 0.808080792427063: Spikes at time step(s) [0]\n",
      "Pixel 0.8181818127632141: Spikes at time step(s) [0]\n",
      "Pixel 0.8282828330993652: Spikes at time step(s) [0]\n",
      "Pixel 0.8383838534355164: Spikes at time step(s) [0]\n",
      "Pixel 0.8484848737716675: Spikes at time step(s) [0]\n",
      "Pixel 0.8585858345031738: Spikes at time step(s) [0]\n",
      "Pixel 0.868686854839325: Spikes at time step(s) [0]\n",
      "Pixel 0.8787878751754761: Spikes at time step(s) [0]\n",
      "Pixel 0.8888888955116272: Spikes at time step(s) [0]\n",
      "Pixel 0.8989899158477783: Spikes at time step(s) [0]\n",
      "Pixel 0.9090909361839294: Spikes at time step(s) [0]\n",
      "Pixel 0.9191918969154358: Spikes at time step(s) [0]\n",
      "Pixel 0.9292929172515869: Spikes at time step(s) [0]\n",
      "Pixel 0.939393937587738: Spikes at time step(s) [0]\n",
      "Pixel 0.9494949579238892: Spikes at time step(s) [0]\n",
      "Pixel 0.9595959782600403: Spikes at time step(s) [0]\n",
      "Pixel 0.9696969985961914: Spikes at time step(s) [0]\n",
      "Pixel 0.9797979593276978: Spikes at time step(s) [0]\n",
      "Pixel 0.9898989796638489: Spikes at time step(s) [0]\n",
      "Pixel 1.0: Spikes at time step(s) [0]\n",
      "\n",
      " ttfe with acquired data :\n",
      "Pixel 0.0: Spikes at time step(s) [3]\n",
      "Pixel 0.010101010091602802: Spikes at time step(s) [3]\n",
      "Pixel 0.020202020183205605: Spikes at time step(s) [2]\n",
      "Pixel 0.03030303120613098: Spikes at time step(s) [2]\n",
      "Pixel 0.04040404036641121: Spikes at time step(s) [2]\n",
      "Pixel 0.05050504952669144: Spikes at time step(s) [2]\n",
      "Pixel 0.06060606241226196: Spikes at time step(s) [2]\n",
      "Pixel 0.07070706784725189: Spikes at time step(s) [2]\n",
      "Pixel 0.08080808073282242: Spikes at time step(s) [2]\n",
      "Pixel 0.09090909361839294: Spikes at time step(s) [2]\n",
      "Pixel 0.10101009905338287: Spikes at time step(s) [2]\n",
      "Pixel 0.1111111119389534: Spikes at time step(s) [2]\n",
      "Pixel 0.12121212482452393: Spikes at time step(s) [2]\n",
      "Pixel 0.13131313025951385: Spikes at time step(s) [2]\n",
      "Pixel 0.14141413569450378: Spikes at time step(s) [2]\n",
      "Pixel 0.1515151560306549: Spikes at time step(s) [2]\n",
      "Pixel 0.16161616146564484: Spikes at time step(s) [2]\n",
      "Pixel 0.17171716690063477: Spikes at time step(s) [1]\n",
      "Pixel 0.1818181872367859: Spikes at time step(s) [1]\n",
      "Pixel 0.19191919267177582: Spikes at time step(s) [1]\n",
      "Pixel 0.20202019810676575: Spikes at time step(s) [1]\n",
      "Pixel 0.21212121844291687: Spikes at time step(s) [1]\n",
      "Pixel 0.2222222238779068: Spikes at time step(s) [1]\n",
      "Pixel 0.23232322931289673: Spikes at time step(s) [1]\n",
      "Pixel 0.24242424964904785: Spikes at time step(s) [1]\n",
      "Pixel 0.2525252401828766: Spikes at time step(s) [1]\n",
      "Pixel 0.2626262605190277: Spikes at time step(s) [1]\n",
      "Pixel 0.27272728085517883: Spikes at time step(s) [1]\n",
      "Pixel 0.28282827138900757: Spikes at time step(s) [1]\n",
      "Pixel 0.2929292917251587: Spikes at time step(s) [1]\n",
      "Pixel 0.3030303120613098: Spikes at time step(s) [1]\n",
      "Pixel 0.31313130259513855: Spikes at time step(s) [1]\n",
      "Pixel 0.3232323229312897: Spikes at time step(s) [0]\n",
      "Pixel 0.3333333432674408: Spikes at time step(s) [0]\n",
      "Pixel 0.34343433380126953: Spikes at time step(s) [0]\n",
      "Pixel 0.35353535413742065: Spikes at time step(s) [0]\n",
      "Pixel 0.3636363744735718: Spikes at time step(s) [0]\n",
      "Pixel 0.3737373650074005: Spikes at time step(s) [0]\n",
      "Pixel 0.38383838534355164: Spikes at time step(s) [0]\n",
      "Pixel 0.39393940567970276: Spikes at time step(s) [0]\n",
      "Pixel 0.4040403962135315: Spikes at time step(s) [0]\n",
      "Pixel 0.4141414165496826: Spikes at time step(s) [0]\n",
      "Pixel 0.42424243688583374: Spikes at time step(s) [0]\n",
      "Pixel 0.4343434274196625: Spikes at time step(s) [0]\n",
      "Pixel 0.4444444477558136: Spikes at time step(s) [0]\n",
      "Pixel 0.4545454680919647: Spikes at time step(s) [0]\n",
      "Pixel 0.46464645862579346: Spikes at time step(s) [0]\n",
      "Pixel 0.4747474789619446: Spikes at time step(s) [0]\n",
      "Pixel 0.4848484992980957: Spikes at time step(s) [0]\n",
      "Pixel 0.49494948983192444: Spikes at time step(s) [0]\n",
      "Pixel 0.5050504803657532: Spikes at time step(s) [0]\n",
      "Pixel 0.5151515007019043: Spikes at time step(s) [0]\n",
      "Pixel 0.5252525210380554: Spikes at time step(s) [0]\n",
      "Pixel 0.5353535413742065: Spikes at time step(s) [0]\n",
      "Pixel 0.5454545617103577: Spikes at time step(s) [0]\n",
      "Pixel 0.5555555820465088: Spikes at time step(s) [0]\n",
      "Pixel 0.5656565427780151: Spikes at time step(s) [0]\n",
      "Pixel 0.5757575631141663: Spikes at time step(s) [0]\n",
      "Pixel 0.5858585834503174: Spikes at time step(s) [0]\n",
      "Pixel 0.5959596037864685: Spikes at time step(s) [0]\n",
      "Pixel 0.6060606241226196: Spikes at time step(s) [0]\n",
      "Pixel 0.6161616444587708: Spikes at time step(s) [0]\n",
      "Pixel 0.6262626051902771: Spikes at time step(s) [0]\n",
      "Pixel 0.6363636255264282: Spikes at time step(s) [0]\n",
      "Pixel 0.6464646458625793: Spikes at time step(s) [0]\n",
      "Pixel 0.6565656661987305: Spikes at time step(s) [0]\n",
      "Pixel 0.6666666865348816: Spikes at time step(s) [0]\n",
      "Pixel 0.6767677068710327: Spikes at time step(s) [0]\n",
      "Pixel 0.6868686676025391: Spikes at time step(s) [0]\n",
      "Pixel 0.6969696879386902: Spikes at time step(s) [0]\n",
      "Pixel 0.7070707082748413: Spikes at time step(s) [0]\n",
      "Pixel 0.7171717286109924: Spikes at time step(s) [0]\n",
      "Pixel 0.7272727489471436: Spikes at time step(s) [0]\n",
      "Pixel 0.7373737096786499: Spikes at time step(s) [0]\n",
      "Pixel 0.747474730014801: Spikes at time step(s) [0]\n",
      "Pixel 0.7575757503509521: Spikes at time step(s) [0]\n",
      "Pixel 0.7676767706871033: Spikes at time step(s) [0]\n",
      "Pixel 0.7777777910232544: Spikes at time step(s) [0]\n",
      "Pixel 0.7878788113594055: Spikes at time step(s) [0]\n",
      "Pixel 0.7979797720909119: Spikes at time step(s) [0]\n",
      "Pixel 0.808080792427063: Spikes at time step(s) [0]\n",
      "Pixel 0.8181818127632141: Spikes at time step(s) [0]\n",
      "Pixel 0.8282828330993652: Spikes at time step(s) [0]\n",
      "Pixel 0.8383838534355164: Spikes at time step(s) [0]\n",
      "Pixel 0.8484848737716675: Spikes at time step(s) [0]\n",
      "Pixel 0.8585858345031738: Spikes at time step(s) [0]\n",
      "Pixel 0.868686854839325: Spikes at time step(s) [0]\n",
      "Pixel 0.8787878751754761: Spikes at time step(s) [0]\n",
      "Pixel 0.8888888955116272: Spikes at time step(s) [0]\n",
      "Pixel 0.8989899158477783: Spikes at time step(s) [0]\n",
      "Pixel 0.9090909361839294: Spikes at time step(s) [0]\n",
      "Pixel 0.9191918969154358: Spikes at time step(s) [0]\n",
      "Pixel 0.9292929172515869: Spikes at time step(s) [0]\n",
      "Pixel 0.939393937587738: Spikes at time step(s) [0]\n",
      "Pixel 0.9494949579238892: Spikes at time step(s) [0]\n",
      "Pixel 0.9595959782600403: Spikes at time step(s) [0]\n",
      "Pixel 0.9696969985961914: Spikes at time step(s) [0]\n",
      "Pixel 0.9797979593276978: Spikes at time step(s) [0]\n",
      "Pixel 0.9898989796638489: Spikes at time step(s) [0]\n",
      "Pixel 1.0: Spikes at time step(s) [0]\n"
     ]
    }
   ],
   "source": [
    "# time-to-first-spike encoding 방식을 통해 encdoing 했을 때 spike가 어떻게 발생하는 지 디버깅하기 위한 부분\n",
    "\n",
    "# 픽셀 값 생성 (0 ~ 1)\n",
    "pixel_values = torch.linspace(0, 1, 100).reshape(1, -1).to('cpu')  #(batch_size, dim_in)\n",
    "print(\"Pixel Values:\", pixel_values)\n",
    "\n",
    "tau = 10\n",
    "threshold = 0.01\n",
    "\n",
    "# snntorch에서 함수를 이용해 ttfs encoding한 결과\n",
    "spike_time1 = latency(pixel_values, num_steps=param['T_sim'], tau=tau, threshold=threshold, clip=False, normalize=False, linear=False, bypass=True)\n",
    "spike_time1 = spike_time1.permute(1, 2, 0)  #(1, N, T_sim)\n",
    "spike_time1_first_spike = torch.zeros_like(spike_time1)\n",
    "for i in range(spike_time1.shape[1]): \n",
    "    first_spike_indices = torch.nonzero(spike_time1[0, i, :])\n",
    "    if len(first_spike_indices) > 0:\n",
    "        first_spike_time = first_spike_indices[0, 0].item()\n",
    "        spike_time1_first_spike[0, i, first_spike_time] = 1 \n",
    "\n",
    "# 직접 구한 데이터를 이용해 ttfs 방식으로 encoding\n",
    "spike_time2 = ttfs_encoding(pixel_values, param['T_sim'])\n",
    "\n",
    "print(\"\\n ttfe spike time with snntorch :\")\n",
    "for i in range(spike_time1_first_spike.shape[1]):\n",
    "    spike_times = torch.nonzero(spike_time1_first_spike[0, i, :]).flatten()\n",
    "    print(f\"Pixel {pixel_values[0, i].item()}: Spikes at time step(s) {spike_times.tolist()}\")\n",
    "\n",
    "print(\"\\n ttfe with acquired data :\")\n",
    "for i in range(spike_time2.shape[1]):\n",
    "    spike_times = torch.nonzero(spike_time2[0, i, :]).flatten()\n",
    "    print(f\"Pixel {pixel_values[0, i].item()}: Spikes at time step(s) {spike_times.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tranning epoch 0: the SNN loss is 2.251962 trainning accuracy: 0.1606 validation accuracy: 0.2043\n",
      "total spike number is 482288.0 elapsed time : 8.5s\n",
      "tranning epoch 1: the SNN loss is 2.215293 trainning accuracy: 0.2445 validation accuracy: 0.2831\n",
      "total spike number is 481148.0 elapsed time : 17.2s\n",
      "tranning epoch 2: the SNN loss is 2.204765 trainning accuracy: 0.3085 validation accuracy: 0.3461\n",
      "total spike number is 480558.0 elapsed time : 24.9s\n",
      "tranning epoch 3: the SNN loss is 2.173622 trainning accuracy: 0.4473 validation accuracy: 0.4276\n",
      "total spike number is 479437.0 elapsed time : 32.7s\n",
      "tranning epoch 4: the SNN loss is 2.140737 trainning accuracy: 0.5224 validation accuracy: 0.5671\n",
      "total spike number is 478509.0 elapsed time : 40.4s\n",
      "tranning epoch 5: the SNN loss is 2.145893 trainning accuracy: 0.5696 validation accuracy: 0.5967\n",
      "total spike number is 478496.0 elapsed time : 48.1s\n",
      "tranning epoch 6: the SNN loss is 2.125846 trainning accuracy: 0.5895 validation accuracy: 0.6219\n",
      "total spike number is 478321.0 elapsed time : 55.8s\n",
      "tranning epoch 7: the SNN loss is 2.128607 trainning accuracy: 0.6258 validation accuracy: 0.6538\n",
      "total spike number is 478242.0 elapsed time : 63.8s\n",
      "tranning epoch 8: the SNN loss is 2.118277 trainning accuracy: 0.6411 validation accuracy: 0.6079\n",
      "total spike number is 477981.0 elapsed time : 71.5s\n",
      "tranning epoch 9: the SNN loss is 2.123037 trainning accuracy: 0.6600 validation accuracy: 0.6910\n",
      "total spike number is 478632.0 elapsed time : 79.1s\n",
      "tranning epoch 10: the SNN loss is 2.118956 trainning accuracy: 0.6652 validation accuracy: 0.6991\n",
      "total spike number is 478702.0 elapsed time : 86.7s\n",
      "tranning epoch 11: the SNN loss is 2.109062 trainning accuracy: 0.6910 validation accuracy: 0.6897\n",
      "total spike number is 478163.0 elapsed time : 94.4s\n",
      "tranning epoch 12: the SNN loss is 2.088593 trainning accuracy: 0.7040 validation accuracy: 0.7191\n",
      "total spike number is 478939.0 elapsed time : 102.1s\n",
      "tranning epoch 13: the SNN loss is 2.101299 trainning accuracy: 0.7096 validation accuracy: 0.6842\n",
      "total spike number is 479398.0 elapsed time : 109.8s\n",
      "tranning epoch 14: the SNN loss is 2.091785 trainning accuracy: 0.7187 validation accuracy: 0.7307\n",
      "total spike number is 479218.0 elapsed time : 117.6s\n",
      "tranning epoch 15: the SNN loss is 2.076020 trainning accuracy: 0.7391 validation accuracy: 0.7387\n",
      "total spike number is 478797.0 elapsed time : 125.3s\n",
      "tranning epoch 16: the SNN loss is 2.087918 trainning accuracy: 0.7405 validation accuracy: 0.7456\n",
      "total spike number is 479384.0 elapsed time : 133.4s\n",
      "tranning epoch 17: the SNN loss is 2.084291 trainning accuracy: 0.7535 validation accuracy: 0.7517\n",
      "total spike number is 479357.0 elapsed time : 141.3s\n",
      "tranning epoch 18: the SNN loss is 2.068269 trainning accuracy: 0.7602 validation accuracy: 0.7623\n",
      "total spike number is 479763.0 elapsed time : 149.3s\n",
      "tranning epoch 19: the SNN loss is 2.082217 trainning accuracy: 0.7750 validation accuracy: 0.7816\n",
      "total spike number is 479566.0 elapsed time : 157.5s\n",
      "tranning epoch 20: the SNN loss is 2.060415 trainning accuracy: 0.7860 validation accuracy: 0.7848\n",
      "total spike number is 479628.0 elapsed time : 165.2s\n",
      "tranning epoch 21: the SNN loss is 2.078621 trainning accuracy: 0.7890 validation accuracy: 0.7969\n",
      "total spike number is 479712.0 elapsed time : 172.8s\n",
      "tranning epoch 22: the SNN loss is 2.071894 trainning accuracy: 0.7906 validation accuracy: 0.7899\n",
      "total spike number is 479327.0 elapsed time : 180.5s\n",
      "tranning epoch 23: the SNN loss is 2.044077 trainning accuracy: 0.7926 validation accuracy: 0.8011\n",
      "total spike number is 479891.0 elapsed time : 188.4s\n",
      "tranning epoch 24: the SNN loss is 2.055808 trainning accuracy: 0.8004 validation accuracy: 0.7893\n",
      "total spike number is 479619.0 elapsed time : 196.5s\n",
      "tranning epoch 25: the SNN loss is 2.042108 trainning accuracy: 0.8077 validation accuracy: 0.8121\n",
      "total spike number is 479883.0 elapsed time : 204.6s\n",
      "tranning epoch 26: the SNN loss is 2.046787 trainning accuracy: 0.8101 validation accuracy: 0.7941\n",
      "total spike number is 479788.0 elapsed time : 212.5s\n",
      "tranning epoch 27: the SNN loss is 2.070448 trainning accuracy: 0.8111 validation accuracy: 0.8163\n",
      "total spike number is 479965.0 elapsed time : 220.6s\n",
      "tranning epoch 28: the SNN loss is 2.057119 trainning accuracy: 0.8187 validation accuracy: 0.8197\n",
      "total spike number is 479933.0 elapsed time : 228.7s\n",
      "tranning epoch 29: the SNN loss is 2.038070 trainning accuracy: 0.8203 validation accuracy: 0.8260\n",
      "total spike number is 479939.0 elapsed time : 236.7s\n",
      "tranning epoch 30: the SNN loss is 2.033303 trainning accuracy: 0.8267 validation accuracy: 0.8297\n",
      "total spike number is 479856.0 elapsed time : 244.4s\n",
      "tranning epoch 31: the SNN loss is 2.041346 trainning accuracy: 0.8288 validation accuracy: 0.8041\n",
      "total spike number is 480020.0 elapsed time : 252.0s\n",
      "tranning epoch 32: the SNN loss is 2.050460 trainning accuracy: 0.8280 validation accuracy: 0.8290\n",
      "total spike number is 480109.0 elapsed time : 259.9s\n",
      "tranning epoch 33: the SNN loss is 2.045963 trainning accuracy: 0.8297 validation accuracy: 0.8251\n",
      "total spike number is 479794.0 elapsed time : 267.7s\n",
      "tranning epoch 34: the SNN loss is 2.045882 trainning accuracy: 0.8326 validation accuracy: 0.8335\n",
      "total spike number is 480304.0 elapsed time : 275.4s\n",
      "tranning epoch 35: the SNN loss is 2.042421 trainning accuracy: 0.8357 validation accuracy: 0.8280\n",
      "total spike number is 480229.0 elapsed time : 283.0s\n",
      "tranning epoch 36: the SNN loss is 2.033617 trainning accuracy: 0.8364 validation accuracy: 0.8249\n",
      "total spike number is 480277.0 elapsed time : 290.7s\n",
      "tranning epoch 37: the SNN loss is 2.022890 trainning accuracy: 0.8426 validation accuracy: 0.8296\n",
      "total spike number is 480337.0 elapsed time : 298.4s\n",
      "tranning epoch 38: the SNN loss is 2.046400 trainning accuracy: 0.8426 validation accuracy: 0.8428\n",
      "total spike number is 480176.0 elapsed time : 306.1s\n",
      "tranning epoch 39: the SNN loss is 2.031389 trainning accuracy: 0.8443 validation accuracy: 0.8435\n",
      "total spike number is 480687.0 elapsed time : 314.0s\n",
      "tranning epoch 40: the SNN loss is 2.032523 trainning accuracy: 0.8460 validation accuracy: 0.8336\n",
      "total spike number is 480525.0 elapsed time : 321.8s\n",
      "tranning epoch 41: the SNN loss is 2.044234 trainning accuracy: 0.8416 validation accuracy: 0.8245\n",
      "total spike number is 480699.0 elapsed time : 329.6s\n",
      "tranning epoch 42: the SNN loss is 2.036731 trainning accuracy: 0.8467 validation accuracy: 0.8242\n",
      "total spike number is 480764.0 elapsed time : 337.2s\n",
      "tranning epoch 43: the SNN loss is 2.029912 trainning accuracy: 0.8485 validation accuracy: 0.8425\n",
      "total spike number is 480406.0 elapsed time : 344.8s\n",
      "tranning epoch 44: the SNN loss is 2.040036 trainning accuracy: 0.8482 validation accuracy: 0.8312\n",
      "total spike number is 481011.0 elapsed time : 352.6s\n",
      "tranning epoch 45: the SNN loss is 2.028483 trainning accuracy: 0.8486 validation accuracy: 0.8425\n",
      "total spike number is 480919.0 elapsed time : 360.2s\n",
      "tranning epoch 46: the SNN loss is 2.030448 trainning accuracy: 0.8486 validation accuracy: 0.8500\n",
      "total spike number is 480824.0 elapsed time : 367.9s\n",
      "tranning epoch 47: the SNN loss is 2.034290 trainning accuracy: 0.8568 validation accuracy: 0.8319\n",
      "total spike number is 481357.0 elapsed time : 375.5s\n",
      "tranning epoch 48: the SNN loss is 2.018972 trainning accuracy: 0.8534 validation accuracy: 0.8352\n",
      "total spike number is 481252.0 elapsed time : 383.2s\n",
      "tranning epoch 49: the SNN loss is 2.034519 trainning accuracy: 0.8502 validation accuracy: 0.8398\n",
      "total spike number is 481322.0 elapsed time : 391.0s\n",
      "tranning epoch 50: the SNN loss is 2.021678 trainning accuracy: 0.8555 validation accuracy: 0.8319\n",
      "total spike number is 481774.0 elapsed time : 398.8s\n",
      "tranning epoch 51: the SNN loss is 2.026995 trainning accuracy: 0.8536 validation accuracy: 0.8458\n",
      "total spike number is 481442.0 elapsed time : 406.5s\n",
      "tranning epoch 52: the SNN loss is 2.030774 trainning accuracy: 0.8555 validation accuracy: 0.8367\n",
      "total spike number is 481636.0 elapsed time : 414.1s\n",
      "tranning epoch 53: the SNN loss is 2.023584 trainning accuracy: 0.8527 validation accuracy: 0.8346\n",
      "total spike number is 481569.0 elapsed time : 422.3s\n",
      "tranning epoch 54: the SNN loss is 2.026990 trainning accuracy: 0.8533 validation accuracy: 0.8381\n",
      "total spike number is 481720.0 elapsed time : 430.6s\n",
      "tranning epoch 55: the SNN loss is 2.020681 trainning accuracy: 0.8521 validation accuracy: 0.8324\n",
      "total spike number is 481776.0 elapsed time : 438.3s\n",
      "tranning epoch 56: the SNN loss is 2.022542 trainning accuracy: 0.8524 validation accuracy: 0.8194\n",
      "total spike number is 481894.0 elapsed time : 446.0s\n",
      "tranning epoch 57: the SNN loss is 2.012513 trainning accuracy: 0.8525 validation accuracy: 0.8294\n",
      "total spike number is 481734.0 elapsed time : 453.6s\n",
      "tranning epoch 58: the SNN loss is 2.023567 trainning accuracy: 0.8503 validation accuracy: 0.8376\n",
      "total spike number is 481886.0 elapsed time : 461.2s\n",
      "tranning epoch 59: the SNN loss is 2.014694 trainning accuracy: 0.8514 validation accuracy: 0.8421\n",
      "total spike number is 481697.0 elapsed time : 469.1s\n",
      "tranning epoch 60: the SNN loss is 2.015743 trainning accuracy: 0.8535 validation accuracy: 0.8379\n",
      "total spike number is 482109.0 elapsed time : 476.9s\n",
      "tranning epoch 61: the SNN loss is 2.037042 trainning accuracy: 0.8522 validation accuracy: 0.8264\n",
      "total spike number is 481967.0 elapsed time : 484.5s\n",
      "tranning epoch 62: the SNN loss is 2.016224 trainning accuracy: 0.8549 validation accuracy: 0.8412\n",
      "total spike number is 482026.0 elapsed time : 492.2s\n",
      "tranning epoch 63: the SNN loss is 2.012341 trainning accuracy: 0.8534 validation accuracy: 0.8439\n",
      "total spike number is 482368.0 elapsed time : 499.9s\n",
      "tranning epoch 64: the SNN loss is 2.035457 trainning accuracy: 0.8560 validation accuracy: 0.8382\n",
      "total spike number is 482330.0 elapsed time : 507.5s\n",
      "tranning epoch 65: the SNN loss is 2.021621 trainning accuracy: 0.8577 validation accuracy: 0.8453\n",
      "total spike number is 482308.0 elapsed time : 515.3s\n",
      "tranning epoch 66: the SNN loss is 2.026597 trainning accuracy: 0.8577 validation accuracy: 0.8394\n",
      "total spike number is 482558.0 elapsed time : 523.0s\n",
      "tranning epoch 67: the SNN loss is 2.028388 trainning accuracy: 0.8547 validation accuracy: 0.8280\n",
      "total spike number is 482700.0 elapsed time : 530.7s\n",
      "tranning epoch 68: the SNN loss is 2.008556 trainning accuracy: 0.8563 validation accuracy: 0.8407\n",
      "total spike number is 482393.0 elapsed time : 538.3s\n",
      "tranning epoch 69: the SNN loss is 2.007054 trainning accuracy: 0.8541 validation accuracy: 0.8178\n",
      "total spike number is 482780.0 elapsed time : 546.1s\n",
      "tranning epoch 70: the SNN loss is 2.007887 trainning accuracy: 0.8577 validation accuracy: 0.8435\n",
      "total spike number is 482584.0 elapsed time : 553.9s\n",
      "tranning epoch 71: the SNN loss is 2.011081 trainning accuracy: 0.8608 validation accuracy: 0.8441\n",
      "total spike number is 482858.0 elapsed time : 561.7s\n",
      "tranning epoch 72: the SNN loss is 2.006258 trainning accuracy: 0.8578 validation accuracy: 0.8397\n",
      "total spike number is 482717.0 elapsed time : 569.3s\n",
      "tranning epoch 73: the SNN loss is 2.004177 trainning accuracy: 0.8563 validation accuracy: 0.8340\n",
      "total spike number is 482540.0 elapsed time : 576.9s\n",
      "tranning epoch 74: the SNN loss is 2.025628 trainning accuracy: 0.8600 validation accuracy: 0.8441\n",
      "total spike number is 482864.0 elapsed time : 584.5s\n",
      "tranning epoch 75: the SNN loss is 1.996293 trainning accuracy: 0.8619 validation accuracy: 0.8494\n",
      "total spike number is 482798.0 elapsed time : 592.1s\n",
      "tranning epoch 76: the SNN loss is 2.009546 trainning accuracy: 0.8633 validation accuracy: 0.8481\n",
      "total spike number is 482932.0 elapsed time : 599.9s\n",
      "tranning epoch 77: the SNN loss is 2.017285 trainning accuracy: 0.8594 validation accuracy: 0.8496\n",
      "total spike number is 483077.0 elapsed time : 607.7s\n",
      "tranning epoch 78: the SNN loss is 2.015990 trainning accuracy: 0.8578 validation accuracy: 0.8451\n",
      "total spike number is 483107.0 elapsed time : 615.4s\n",
      "tranning epoch 79: the SNN loss is 2.002160 trainning accuracy: 0.8588 validation accuracy: 0.8477\n",
      "total spike number is 483155.0 elapsed time : 623.2s\n",
      "tranning epoch 80: the SNN loss is 2.004352 trainning accuracy: 0.8601 validation accuracy: 0.8432\n",
      "total spike number is 483090.0 elapsed time : 630.9s\n",
      "tranning epoch 81: the SNN loss is 2.001537 trainning accuracy: 0.8611 validation accuracy: 0.8376\n",
      "total spike number is 483215.0 elapsed time : 638.6s\n",
      "tranning epoch 82: the SNN loss is 1.996610 trainning accuracy: 0.8609 validation accuracy: 0.8503\n",
      "total spike number is 483024.0 elapsed time : 646.2s\n",
      "tranning epoch 83: the SNN loss is 2.023568 trainning accuracy: 0.8611 validation accuracy: 0.8444\n",
      "total spike number is 483151.0 elapsed time : 654.0s\n",
      "tranning epoch 84: the SNN loss is 2.015357 trainning accuracy: 0.8588 validation accuracy: 0.8421\n",
      "total spike number is 483461.0 elapsed time : 661.8s\n",
      "tranning epoch 85: the SNN loss is 2.000556 trainning accuracy: 0.8610 validation accuracy: 0.8349\n",
      "total spike number is 483196.0 elapsed time : 669.5s\n",
      "tranning epoch 86: the SNN loss is 2.003448 trainning accuracy: 0.8576 validation accuracy: 0.8480\n",
      "total spike number is 483531.0 elapsed time : 677.1s\n",
      "tranning epoch 87: the SNN loss is 2.010634 trainning accuracy: 0.8606 validation accuracy: 0.8484\n",
      "total spike number is 483717.0 elapsed time : 684.8s\n",
      "tranning epoch 88: the SNN loss is 2.004656 trainning accuracy: 0.8624 validation accuracy: 0.8498\n",
      "total spike number is 484023.0 elapsed time : 692.8s\n",
      "tranning epoch 89: the SNN loss is 2.005171 trainning accuracy: 0.8610 validation accuracy: 0.8366\n",
      "total spike number is 484072.0 elapsed time : 700.9s\n",
      "tranning epoch 90: the SNN loss is 2.000884 trainning accuracy: 0.8621 validation accuracy: 0.8506\n",
      "total spike number is 483801.0 elapsed time : 708.8s\n",
      "tranning epoch 91: the SNN loss is 2.002993 trainning accuracy: 0.8653 validation accuracy: 0.8451\n",
      "total spike number is 484148.0 elapsed time : 716.9s\n",
      "tranning epoch 92: the SNN loss is 2.005735 trainning accuracy: 0.8660 validation accuracy: 0.8401\n",
      "total spike number is 483997.0 elapsed time : 725.2s\n",
      "tranning epoch 93: the SNN loss is 2.017844 trainning accuracy: 0.8676 validation accuracy: 0.8505\n",
      "total spike number is 484349.0 elapsed time : 733.2s\n",
      "tranning epoch 94: the SNN loss is 2.002597 trainning accuracy: 0.8621 validation accuracy: 0.8493\n",
      "total spike number is 484317.0 elapsed time : 741.2s\n",
      "tranning epoch 95: the SNN loss is 2.011377 trainning accuracy: 0.8602 validation accuracy: 0.8495\n",
      "total spike number is 484194.0 elapsed time : 749.3s\n",
      "tranning epoch 96: the SNN loss is 2.004653 trainning accuracy: 0.8644 validation accuracy: 0.8534\n",
      "total spike number is 484445.0 elapsed time : 757.3s\n",
      "tranning epoch 97: the SNN loss is 2.006555 trainning accuracy: 0.8657 validation accuracy: 0.8546\n",
      "total spike number is 484452.0 elapsed time : 765.3s\n",
      "tranning epoch 98: the SNN loss is 1.987705 trainning accuracy: 0.8651 validation accuracy: 0.8501\n",
      "total spike number is 484358.0 elapsed time : 773.4s\n",
      "tranning epoch 99: the SNN loss is 2.004864 trainning accuracy: 0.8654 validation accuracy: 0.8293\n",
      "total spike number is 484385.0 elapsed time : 781.8s\n"
     ]
    }
   ],
   "source": [
    "# Rate Encoding 방식으로 model을 학습85%\n",
    "# Time_step = 20, learning_rate = 0.015, total_spike = 480000, test_accuracy = 84~85%\n",
    "\n",
    "trainset = torchvision.datasets.MNIST(root=param['data_dir'], train=True,\n",
    "                                        download=True, transform=transforms.ToTensor())\n",
    "testset = torchvision.datasets.MNIST(root=param['data_dir'], train=False,\n",
    "                                        download=True, transform=transforms.ToTensor())\n",
    "trainloader = torch.utils.data.DataLoader(dataset=trainset, batch_size=param['batch_size'],\n",
    "                                            shuffle=True, drop_last=True, num_workers=2, pin_memory=True)\n",
    "testloader = torch.utils.data.DataLoader(dataset=testset, batch_size=param['batch_size'],\n",
    "                                            shuffle=False, drop_last=True, num_workers=2, pin_memory=True)\n",
    "\n",
    "#Train the SNN with BP\n",
    "net = Three_Layer_SNN(param).to(device)\n",
    "loss_func = torch.nn.CrossEntropyLoss().to(device)\n",
    "optim = torch.optim.Adam(net.parameters(), param['learning_rate'])\n",
    "\n",
    "start = time.time()\n",
    "for epoch in range(param['epoch']):\n",
    "    net.train()\n",
    "    train_accuracy = []\n",
    "    \n",
    "    for img, label in trainloader:\n",
    "        img = img.reshape(-1, input_dimmension)\n",
    "        spike_num_img = torch.zeros(param['batch_size'], param['dim_out']).to(device)\n",
    "\n",
    "        # using gpu\n",
    "        img, label = img.to(device), label.to(device)\n",
    "    \n",
    "        # rate coding method\n",
    "        spike_time = rate_encoding(img, param['T_sim'])\n",
    "\n",
    "        net.reset_() #set the neuron voltage as reset voltage\n",
    "        for t in range(param['T_sim']):\n",
    "            # rate coding method\n",
    "            new_img = spike_time[:, :, t]  \n",
    "            out_spike, total_spike = net(new_img)\n",
    "            spike_num_img += out_spike \n",
    "\n",
    "        spike_rate = spike_num_img/param['T_sim']  # /26\n",
    "        loss = loss_func(spike_rate, label)\n",
    "\n",
    "        #net.zero_grad()\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            net.reset_()    # reset the neuron voltage every batch, to ensure independency between batchs\n",
    "            net.quant_()    # quantize the weights after weight update\n",
    "\n",
    "        train_accuracy.append((spike_rate.max(1)[1] == label).float().mean().item())\n",
    "    accuracy_epoch = np.mean(train_accuracy)\n",
    "    print('tranning epoch %d: the SNN loss is %.6f' %(epoch, loss), end=' ')\n",
    "    print('trainning accuracy: %.4f' %accuracy_epoch, end=' ')\n",
    "    \n",
    "# validation by testset every epoch to see if the network is overfitted\n",
    "    net.eval()\n",
    "    validation_accuracy = []\n",
    "    with torch.no_grad():\n",
    "        for img_test, label_test in testloader:\n",
    "            img_test = img_test.reshape(-1, input_dimmension)\n",
    "            spike_num_img_test = torch.zeros(param['batch_size'], param['dim_out']).to(device)\n",
    "\n",
    "            # using gpu\n",
    "            img_test, label_test = img_test.to(device), label_test.to(device)\n",
    "\n",
    "            # rate coding method\n",
    "            spike_time = rate_encoding(img_test, param['T_sim'])\n",
    "            \n",
    "            total_spike = spike_time.sum()\n",
    "            net.reset_() #set the neuron voltage as reset voltage\n",
    "            for t in range(param['T_sim']):\n",
    "                # rate coding method\n",
    "                new_test_img = spike_time[:, :, t]  \n",
    "                out_spike, spike_num = net(new_test_img)\n",
    "                spike_num_img_test += out_spike \n",
    "                total_spike += spike_num\n",
    "                \n",
    "            validation_accuracy.append((spike_num_img_test.max(1)[1]==label_test).float().mean().item())\n",
    "        accuracy_val = np.mean(validation_accuracy)\n",
    "        print('validation accuracy: %.4f' %accuracy_val)\n",
    "        print('total spike number is {}' .format(total_spike), end = \" \") \n",
    "        print('elapsed time : {0:.1f}s' .format(time.time() - start))\n",
    "\n",
    "    with open(param['train_file'], 'a') as f_t:\n",
    "        s = str(epoch).ljust(6, ' ') + str(round(loss.item(), 6)).ljust(12, ' ')\n",
    "        s += str(round(accuracy_epoch, 4)).ljust(10, ' ') + str(round(accuracy_val, 4)).ljust(10, ' ')\n",
    "        s += str(int(total_spike.item())).ljust(12, ' ') + '\\n'\n",
    "        f_t.write(s)\n",
    "\n",
    "torch.save(net.state_dict(), param['model_dir'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tranning epoch 0: the SNN loss is 1.714737 trainning accuracy: 0.4948 validation accuracy: 0.5894\n",
      "total spike number is 208787.0 elapsed time : 7.8s\n",
      "tranning epoch 1: the SNN loss is 1.664072 trainning accuracy: 0.6348 validation accuracy: 0.6699\n",
      "total spike number is 210679.0 elapsed time : 15.5s\n",
      "tranning epoch 2: the SNN loss is 1.616650 trainning accuracy: 0.6820 validation accuracy: 0.7195\n",
      "total spike number is 209045.0 elapsed time : 23.2s\n",
      "tranning epoch 3: the SNN loss is 1.601045 trainning accuracy: 0.7155 validation accuracy: 0.7260\n",
      "total spike number is 208427.0 elapsed time : 31.0s\n",
      "tranning epoch 4: the SNN loss is 1.612205 trainning accuracy: 0.7367 validation accuracy: 0.7642\n",
      "total spike number is 207594.0 elapsed time : 38.7s\n",
      "tranning epoch 5: the SNN loss is 1.595583 trainning accuracy: 0.7588 validation accuracy: 0.7830\n",
      "total spike number is 209105.0 elapsed time : 46.5s\n",
      "tranning epoch 6: the SNN loss is 1.613802 trainning accuracy: 0.7703 validation accuracy: 0.7988\n",
      "total spike number is 208830.0 elapsed time : 54.2s\n",
      "tranning epoch 7: the SNN loss is 1.584972 trainning accuracy: 0.7753 validation accuracy: 0.7642\n",
      "total spike number is 208503.0 elapsed time : 61.9s\n",
      "tranning epoch 8: the SNN loss is 1.576725 trainning accuracy: 0.7888 validation accuracy: 0.7733\n",
      "total spike number is 208067.0 elapsed time : 69.7s\n",
      "tranning epoch 9: the SNN loss is 1.571311 trainning accuracy: 0.8046 validation accuracy: 0.8084\n",
      "total spike number is 208432.0 elapsed time : 77.3s\n",
      "tranning epoch 10: the SNN loss is 1.544203 trainning accuracy: 0.8112 validation accuracy: 0.8196\n",
      "total spike number is 208089.0 elapsed time : 85.1s\n",
      "tranning epoch 11: the SNN loss is 1.611493 trainning accuracy: 0.8155 validation accuracy: 0.7553\n",
      "total spike number is 208512.0 elapsed time : 92.8s\n",
      "tranning epoch 12: the SNN loss is 1.517721 trainning accuracy: 0.8122 validation accuracy: 0.8036\n",
      "total spike number is 208462.0 elapsed time : 101.3s\n",
      "tranning epoch 13: the SNN loss is 1.557136 trainning accuracy: 0.8248 validation accuracy: 0.8101\n",
      "total spike number is 208396.0 elapsed time : 110.0s\n",
      "tranning epoch 14: the SNN loss is 1.576069 trainning accuracy: 0.8256 validation accuracy: 0.8301\n",
      "total spike number is 208374.0 elapsed time : 118.4s\n",
      "tranning epoch 15: the SNN loss is 1.532282 trainning accuracy: 0.8315 validation accuracy: 0.8344\n",
      "total spike number is 207784.0 elapsed time : 126.9s\n",
      "tranning epoch 16: the SNN loss is 1.539601 trainning accuracy: 0.8314 validation accuracy: 0.8302\n",
      "total spike number is 207644.0 elapsed time : 135.4s\n",
      "tranning epoch 17: the SNN loss is 1.522981 trainning accuracy: 0.8288 validation accuracy: 0.8120\n",
      "total spike number is 207096.0 elapsed time : 144.0s\n",
      "tranning epoch 18: the SNN loss is 1.563838 trainning accuracy: 0.8341 validation accuracy: 0.8365\n",
      "total spike number is 206871.0 elapsed time : 152.6s\n",
      "tranning epoch 19: the SNN loss is 1.552806 trainning accuracy: 0.8352 validation accuracy: 0.8101\n",
      "total spike number is 206575.0 elapsed time : 161.1s\n",
      "tranning epoch 20: the SNN loss is 1.560220 trainning accuracy: 0.8321 validation accuracy: 0.8546\n",
      "total spike number is 208670.0 elapsed time : 169.8s\n",
      "tranning epoch 21: the SNN loss is 1.554774 trainning accuracy: 0.8435 validation accuracy: 0.8351\n",
      "total spike number is 207890.0 elapsed time : 178.3s\n",
      "tranning epoch 22: the SNN loss is 1.570471 trainning accuracy: 0.8348 validation accuracy: 0.8484\n",
      "total spike number is 208248.0 elapsed time : 186.8s\n",
      "tranning epoch 23: the SNN loss is 1.524233 trainning accuracy: 0.8340 validation accuracy: 0.8361\n",
      "total spike number is 208311.0 elapsed time : 195.5s\n",
      "tranning epoch 24: the SNN loss is 1.540002 trainning accuracy: 0.8454 validation accuracy: 0.8205\n",
      "total spike number is 207895.0 elapsed time : 204.0s\n",
      "tranning epoch 25: the SNN loss is 1.533905 trainning accuracy: 0.8451 validation accuracy: 0.8643\n",
      "total spike number is 207296.0 elapsed time : 212.6s\n",
      "tranning epoch 26: the SNN loss is 1.506164 trainning accuracy: 0.8512 validation accuracy: 0.8428\n",
      "total spike number is 207458.0 elapsed time : 220.3s\n",
      "tranning epoch 27: the SNN loss is 1.590623 trainning accuracy: 0.8346 validation accuracy: 0.8439\n",
      "total spike number is 207352.0 elapsed time : 228.0s\n",
      "tranning epoch 28: the SNN loss is 1.534129 trainning accuracy: 0.8483 validation accuracy: 0.8358\n",
      "total spike number is 206999.0 elapsed time : 235.7s\n",
      "tranning epoch 29: the SNN loss is 1.535748 trainning accuracy: 0.8491 validation accuracy: 0.8370\n",
      "total spike number is 207141.0 elapsed time : 243.4s\n",
      "tranning epoch 30: the SNN loss is 1.543626 trainning accuracy: 0.8512 validation accuracy: 0.8497\n",
      "total spike number is 208258.0 elapsed time : 251.1s\n",
      "tranning epoch 31: the SNN loss is 1.541807 trainning accuracy: 0.8455 validation accuracy: 0.8492\n",
      "total spike number is 207531.0 elapsed time : 259.0s\n",
      "tranning epoch 32: the SNN loss is 1.525803 trainning accuracy: 0.8457 validation accuracy: 0.8550\n",
      "total spike number is 207843.0 elapsed time : 266.7s\n",
      "tranning epoch 33: the SNN loss is 1.533244 trainning accuracy: 0.8463 validation accuracy: 0.8361\n",
      "total spike number is 208642.0 elapsed time : 274.7s\n",
      "tranning epoch 34: the SNN loss is 1.523955 trainning accuracy: 0.8493 validation accuracy: 0.8453\n",
      "total spike number is 209062.0 elapsed time : 283.1s\n",
      "tranning epoch 35: the SNN loss is 1.547902 trainning accuracy: 0.8497 validation accuracy: 0.8429\n",
      "total spike number is 208658.0 elapsed time : 291.7s\n",
      "tranning epoch 36: the SNN loss is 1.551079 trainning accuracy: 0.8462 validation accuracy: 0.8570\n",
      "total spike number is 208776.0 elapsed time : 299.8s\n",
      "tranning epoch 37: the SNN loss is 1.551021 trainning accuracy: 0.8481 validation accuracy: 0.8368\n",
      "total spike number is 209684.0 elapsed time : 307.5s\n",
      "tranning epoch 38: the SNN loss is 1.509986 trainning accuracy: 0.8548 validation accuracy: 0.8623\n",
      "total spike number is 209842.0 elapsed time : 315.4s\n",
      "tranning epoch 39: the SNN loss is 1.542250 trainning accuracy: 0.8439 validation accuracy: 0.8376\n",
      "total spike number is 209289.0 elapsed time : 324.0s\n",
      "tranning epoch 40: the SNN loss is 1.547083 trainning accuracy: 0.8450 validation accuracy: 0.8364\n",
      "total spike number is 209653.0 elapsed time : 332.6s\n",
      "tranning epoch 41: the SNN loss is 1.507518 trainning accuracy: 0.8500 validation accuracy: 0.8519\n",
      "total spike number is 209679.0 elapsed time : 341.3s\n",
      "tranning epoch 42: the SNN loss is 1.541975 trainning accuracy: 0.8567 validation accuracy: 0.8669\n",
      "total spike number is 210496.0 elapsed time : 350.0s\n",
      "tranning epoch 43: the SNN loss is 1.524155 trainning accuracy: 0.8511 validation accuracy: 0.8577\n",
      "total spike number is 210294.0 elapsed time : 358.5s\n",
      "tranning epoch 44: the SNN loss is 1.540157 trainning accuracy: 0.8527 validation accuracy: 0.8420\n",
      "total spike number is 210473.0 elapsed time : 367.2s\n",
      "tranning epoch 45: the SNN loss is 1.534914 trainning accuracy: 0.8533 validation accuracy: 0.8555\n",
      "total spike number is 210734.0 elapsed time : 375.9s\n",
      "tranning epoch 46: the SNN loss is 1.545282 trainning accuracy: 0.8568 validation accuracy: 0.8657\n",
      "total spike number is 210419.0 elapsed time : 384.3s\n",
      "tranning epoch 47: the SNN loss is 1.535657 trainning accuracy: 0.8595 validation accuracy: 0.8704\n",
      "total spike number is 210684.0 elapsed time : 392.8s\n",
      "tranning epoch 48: the SNN loss is 1.519669 trainning accuracy: 0.8639 validation accuracy: 0.8262\n",
      "total spike number is 211058.0 elapsed time : 401.4s\n",
      "tranning epoch 49: the SNN loss is 1.525422 trainning accuracy: 0.8611 validation accuracy: 0.8681\n",
      "total spike number is 210805.0 elapsed time : 410.0s\n",
      "tranning epoch 50: the SNN loss is 1.519601 trainning accuracy: 0.8658 validation accuracy: 0.8493\n",
      "total spike number is 209768.0 elapsed time : 418.6s\n",
      "tranning epoch 51: the SNN loss is 1.568660 trainning accuracy: 0.8609 validation accuracy: 0.8547\n",
      "total spike number is 209525.0 elapsed time : 427.1s\n",
      "tranning epoch 52: the SNN loss is 1.547443 trainning accuracy: 0.8525 validation accuracy: 0.8345\n",
      "total spike number is 209449.0 elapsed time : 435.8s\n",
      "tranning epoch 53: the SNN loss is 1.552400 trainning accuracy: 0.8503 validation accuracy: 0.8330\n",
      "total spike number is 209644.0 elapsed time : 444.3s\n",
      "tranning epoch 54: the SNN loss is 1.522907 trainning accuracy: 0.8542 validation accuracy: 0.8516\n",
      "total spike number is 209822.0 elapsed time : 452.2s\n",
      "tranning epoch 55: the SNN loss is 1.525018 trainning accuracy: 0.8538 validation accuracy: 0.8318\n",
      "total spike number is 209604.0 elapsed time : 460.3s\n",
      "tranning epoch 56: the SNN loss is 1.486677 trainning accuracy: 0.8571 validation accuracy: 0.8698\n",
      "total spike number is 210262.0 elapsed time : 468.8s\n",
      "tranning epoch 57: the SNN loss is 1.534356 trainning accuracy: 0.8542 validation accuracy: 0.8538\n",
      "total spike number is 209911.0 elapsed time : 477.3s\n",
      "tranning epoch 58: the SNN loss is 1.531051 trainning accuracy: 0.8634 validation accuracy: 0.8610\n",
      "total spike number is 210704.0 elapsed time : 486.1s\n",
      "tranning epoch 59: the SNN loss is 1.540699 trainning accuracy: 0.8655 validation accuracy: 0.8177\n",
      "total spike number is 210739.0 elapsed time : 494.6s\n",
      "tranning epoch 60: the SNN loss is 1.534029 trainning accuracy: 0.8537 validation accuracy: 0.8495\n",
      "total spike number is 210573.0 elapsed time : 503.2s\n",
      "tranning epoch 61: the SNN loss is 1.528122 trainning accuracy: 0.8607 validation accuracy: 0.8591\n",
      "total spike number is 210385.0 elapsed time : 511.9s\n",
      "tranning epoch 62: the SNN loss is 1.514384 trainning accuracy: 0.8548 validation accuracy: 0.8491\n",
      "total spike number is 210115.0 elapsed time : 520.5s\n",
      "tranning epoch 63: the SNN loss is 1.527459 trainning accuracy: 0.8521 validation accuracy: 0.8613\n",
      "total spike number is 209344.0 elapsed time : 529.1s\n",
      "tranning epoch 64: the SNN loss is 1.526372 trainning accuracy: 0.8672 validation accuracy: 0.8500\n",
      "total spike number is 209091.0 elapsed time : 537.7s\n",
      "tranning epoch 65: the SNN loss is 1.552291 trainning accuracy: 0.8624 validation accuracy: 0.8539\n",
      "total spike number is 209390.0 elapsed time : 546.3s\n",
      "tranning epoch 66: the SNN loss is 1.534918 trainning accuracy: 0.8548 validation accuracy: 0.8247\n",
      "total spike number is 209891.0 elapsed time : 553.9s\n",
      "tranning epoch 67: the SNN loss is 1.523826 trainning accuracy: 0.8579 validation accuracy: 0.8358\n",
      "total spike number is 209646.0 elapsed time : 561.5s\n",
      "tranning epoch 68: the SNN loss is 1.521481 trainning accuracy: 0.8654 validation accuracy: 0.8382\n",
      "total spike number is 209776.0 elapsed time : 569.3s\n",
      "tranning epoch 69: the SNN loss is 1.519371 trainning accuracy: 0.8573 validation accuracy: 0.8389\n",
      "total spike number is 209651.0 elapsed time : 578.0s\n",
      "tranning epoch 70: the SNN loss is 1.526450 trainning accuracy: 0.8604 validation accuracy: 0.8680\n",
      "total spike number is 209489.0 elapsed time : 585.8s\n",
      "tranning epoch 71: the SNN loss is 1.534492 trainning accuracy: 0.8636 validation accuracy: 0.8618\n",
      "total spike number is 209853.0 elapsed time : 593.4s\n",
      "tranning epoch 72: the SNN loss is 1.534997 trainning accuracy: 0.8670 validation accuracy: 0.8847\n",
      "total spike number is 210403.0 elapsed time : 601.1s\n",
      "tranning epoch 73: the SNN loss is 1.534516 trainning accuracy: 0.8661 validation accuracy: 0.8610\n",
      "total spike number is 210231.0 elapsed time : 608.8s\n",
      "tranning epoch 74: the SNN loss is 1.558893 trainning accuracy: 0.8640 validation accuracy: 0.8455\n",
      "total spike number is 211402.0 elapsed time : 616.8s\n",
      "tranning epoch 75: the SNN loss is 1.546162 trainning accuracy: 0.8620 validation accuracy: 0.8387\n",
      "total spike number is 211320.0 elapsed time : 624.5s\n",
      "tranning epoch 76: the SNN loss is 1.511636 trainning accuracy: 0.8645 validation accuracy: 0.8617\n",
      "total spike number is 210583.0 elapsed time : 632.1s\n",
      "tranning epoch 77: the SNN loss is 1.529887 trainning accuracy: 0.8651 validation accuracy: 0.8643\n",
      "total spike number is 211033.0 elapsed time : 639.9s\n",
      "tranning epoch 78: the SNN loss is 1.513215 trainning accuracy: 0.8682 validation accuracy: 0.8517\n",
      "total spike number is 209917.0 elapsed time : 647.7s\n",
      "tranning epoch 79: the SNN loss is 1.532405 trainning accuracy: 0.8660 validation accuracy: 0.8757\n",
      "total spike number is 209603.0 elapsed time : 655.5s\n",
      "tranning epoch 80: the SNN loss is 1.554746 trainning accuracy: 0.8672 validation accuracy: 0.8497\n",
      "total spike number is 208886.0 elapsed time : 663.2s\n",
      "tranning epoch 81: the SNN loss is 1.514025 trainning accuracy: 0.8690 validation accuracy: 0.8688\n",
      "total spike number is 209731.0 elapsed time : 671.1s\n",
      "tranning epoch 82: the SNN loss is 1.519248 trainning accuracy: 0.8616 validation accuracy: 0.8678\n",
      "total spike number is 210213.0 elapsed time : 679.0s\n",
      "tranning epoch 83: the SNN loss is 1.526602 trainning accuracy: 0.8646 validation accuracy: 0.8494\n",
      "total spike number is 209958.0 elapsed time : 686.8s\n",
      "tranning epoch 84: the SNN loss is 1.487746 trainning accuracy: 0.8660 validation accuracy: 0.8458\n",
      "total spike number is 209553.0 elapsed time : 694.5s\n",
      "tranning epoch 85: the SNN loss is 1.547062 trainning accuracy: 0.8665 validation accuracy: 0.8554\n",
      "total spike number is 210875.0 elapsed time : 702.3s\n",
      "tranning epoch 86: the SNN loss is 1.539391 trainning accuracy: 0.8711 validation accuracy: 0.8709\n",
      "total spike number is 210794.0 elapsed time : 709.9s\n",
      "tranning epoch 87: the SNN loss is 1.510224 trainning accuracy: 0.8670 validation accuracy: 0.8668\n",
      "total spike number is 210923.0 elapsed time : 717.8s\n",
      "tranning epoch 88: the SNN loss is 1.520670 trainning accuracy: 0.8617 validation accuracy: 0.8561\n",
      "total spike number is 210778.0 elapsed time : 726.6s\n",
      "tranning epoch 89: the SNN loss is 1.520900 trainning accuracy: 0.8649 validation accuracy: 0.8630\n",
      "total spike number is 210461.0 elapsed time : 735.2s\n",
      "tranning epoch 90: the SNN loss is 1.531660 trainning accuracy: 0.8704 validation accuracy: 0.8609\n",
      "total spike number is 210316.0 elapsed time : 743.8s\n",
      "tranning epoch 91: the SNN loss is 1.555255 trainning accuracy: 0.8761 validation accuracy: 0.8363\n",
      "total spike number is 210953.0 elapsed time : 752.4s\n",
      "tranning epoch 92: the SNN loss is 1.567035 trainning accuracy: 0.8698 validation accuracy: 0.8517\n",
      "total spike number is 211438.0 elapsed time : 761.1s\n",
      "tranning epoch 93: the SNN loss is 1.520817 trainning accuracy: 0.8710 validation accuracy: 0.8365\n",
      "total spike number is 211273.0 elapsed time : 769.7s\n",
      "tranning epoch 94: the SNN loss is 1.494490 trainning accuracy: 0.8650 validation accuracy: 0.8627\n",
      "total spike number is 212025.0 elapsed time : 778.5s\n",
      "tranning epoch 95: the SNN loss is 1.509399 trainning accuracy: 0.8608 validation accuracy: 0.8442\n",
      "total spike number is 212117.0 elapsed time : 786.2s\n",
      "tranning epoch 96: the SNN loss is 1.533418 trainning accuracy: 0.8630 validation accuracy: 0.8758\n",
      "total spike number is 211451.0 elapsed time : 794.0s\n",
      "tranning epoch 97: the SNN loss is 1.511313 trainning accuracy: 0.8630 validation accuracy: 0.8546\n",
      "total spike number is 211688.0 elapsed time : 802.4s\n",
      "tranning epoch 98: the SNN loss is 1.547130 trainning accuracy: 0.8652 validation accuracy: 0.8476\n",
      "total spike number is 212571.0 elapsed time : 811.0s\n",
      "tranning epoch 99: the SNN loss is 1.511564 trainning accuracy: 0.8703 validation accuracy: 0.8544\n",
      "total spike number is 212823.0 elapsed time : 819.5s\n"
     ]
    }
   ],
   "source": [
    "# Time-to-first-spike encoding \n",
    "# Time_step = 20, learning_rate = 0.015, total_spike = 210000, test_accuracy = 84%\n",
    "\n",
    "trainset = torchvision.datasets.MNIST(root=param['data_dir'], train=True,\n",
    "                                        download=True, transform=transforms.ToTensor())\n",
    "testset = torchvision.datasets.MNIST(root=param['data_dir'], train=False,\n",
    "                                        download=True, transform=transforms.ToTensor())\n",
    "trainloader = torch.utils.data.DataLoader(dataset=trainset, batch_size=param['batch_size'],\n",
    "                                            shuffle=True, drop_last=True, num_workers=2, pin_memory=True)\n",
    "testloader = torch.utils.data.DataLoader(dataset=testset, batch_size=param['batch_size'],\n",
    "                                            shuffle=False, drop_last=True, num_workers=2, pin_memory=True)\n",
    "\n",
    "#Train the SNN with BP\n",
    "net = Three_Layer_SNN(param).to(device)\n",
    "loss_func = torch.nn.CrossEntropyLoss().to(device)\n",
    "optim = torch.optim.Adam(net.parameters(), param['learning_rate'])\n",
    "\n",
    "start = time.time()\n",
    "for epoch in range(param['epoch']):\n",
    "    net.train()\n",
    "    train_accuracy = []\n",
    "    \n",
    "    for img, label in trainloader:\n",
    "        img = img.reshape(-1, input_dimmension)\n",
    "        spike_num_img = torch.zeros(param['batch_size'], param['dim_out']).to(device)\n",
    "\n",
    "        # using gpu\n",
    "        img, label = img.to(device), label.to(device)\n",
    "        \n",
    "        # Time-to-first spike coding method\n",
    "        #spike_time = latency(img, num_steps=param['T_sim'], tau=10, threshold=0.01, clip=False, normalize=False, linear=False, bypass=True)\n",
    "        spike_time = ttfs_encoding(img, param['T_sim'])\n",
    "        mask = torch.ones(param['batch_size'], 1).to(device)\n",
    "\n",
    "        net.reset_() #set the neuron voltage as reset voltage\n",
    "        for t in range(param['T_sim']):\n",
    "            # Time-to-first spike coding method\n",
    "            #new_img = spike_time[t]\n",
    "            new_img = spike_time[:, :, t]  \n",
    "            out_spike, _ = net(new_img)\n",
    "            out_spike *= mask\n",
    "            spike_num_img += out_spike\n",
    "            # update mask\n",
    "            spike_detected = torch.any(out_spike > 0, dim=1, keepdim=True) \n",
    "            mask = mask * (~spike_detected) \n",
    "        spike_rate = spike_num_img\n",
    "        loss = loss_func(spike_rate, label)\n",
    "\n",
    "        #net.zero_grad()\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            net.reset_()    # reset the neuron voltage every batch, to ensure independency between batchs\n",
    "            net.quant_()    # quantize the weights after weight update\n",
    "\n",
    "        train_accuracy.append((spike_rate.max(1)[1] == label).float().mean().item())\n",
    "        \n",
    "    accuracy_epoch = np.mean(train_accuracy)\n",
    "    print('tranning epoch %d: the SNN loss is %.6f' %(epoch, loss), end=' ')\n",
    "    print('trainning accuracy: %.4f' %accuracy_epoch, end=' ')\n",
    "    \n",
    "# validation by testset every epoch to see if the network is overfitted\n",
    "    net.eval()\n",
    "    validation_accuracy = []\n",
    "    with torch.no_grad():\n",
    "        for img_test, label_test in testloader:\n",
    "            img_test = img_test.reshape(-1, input_dimmension)\n",
    "            spike_num_img_test = torch.zeros(param['batch_size'], param['dim_out']).to(device)\n",
    "\n",
    "            # using gpu\n",
    "            img_test, label_test = img_test.to(device), label_test.to(device)\n",
    "            \n",
    "            # Time-to-first spike coding method\n",
    "            #spike_time = latency(img_test, num_steps=param['T_sim'], tau=10, threshold=0.01, clip=False, normalize=False, linear=False, bypass = True)\n",
    "            spike_time = ttfs_encoding(img_test, param['T_sim'])\n",
    "            mask = torch.ones(param['batch_size'], 1).to(device)\n",
    "            \n",
    "            total_spike = spike_time.sum()\n",
    "            net.reset_() #set the neuron voltage as reset voltage\n",
    "            for t in range(param['T_sim']):\n",
    "                # Time-to-first spike coding method\n",
    "                # new_test_img = spike_time[t]\n",
    "                new_test_img = spike_time[:, :, t]\n",
    "                out_spike, spike_num = net(new_test_img)\n",
    "                out_spike *= mask\n",
    "                spike_num_img_test += out_spike\n",
    "                \n",
    "                # update mask\n",
    "                spike_detected = torch.any(out_spike > 0, dim=1, keepdim=True) \n",
    "                mask = mask * (~spike_detected) \n",
    "                \n",
    "                total_spike += spike_num\n",
    "                \n",
    "            validation_accuracy.append((spike_num_img_test.max(1)[1]==label_test).float().mean().item())\n",
    "        accuracy_val = np.mean(validation_accuracy)\n",
    "        print('validation accuracy: %.4f' %accuracy_val)\n",
    "        print('total spike number is {}' .format(total_spike), end = \" \") \n",
    "        print('elapsed time : {0:.1f}s' .format(time.time() - start))\n",
    "\n",
    "    with open(param['train_file'], 'a') as f_t:\n",
    "        s = str(epoch).ljust(6, ' ') + str(round(loss.item(), 6)).ljust(12, ' ')\n",
    "        s += str(round(accuracy_epoch, 4)).ljust(10, ' ') + str(round(accuracy_val, 4)).ljust(10, ' ')\n",
    "        s += str(int(total_spike.item())).ljust(12, ' ') + '\\n'\n",
    "        f_t.write(s)\n",
    "\n",
    "torch.save(net.state_dict(), param['model_dir'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Model, please wait......\n",
      "Model loaded successfully!\n",
      "Test Accuracy: 85.44%\n"
     ]
    }
   ],
   "source": [
    "# Test process after training\n",
    "net_test = Three_Layer_SNN(param).to(device)\n",
    "print('Loading Model, please wait......')\n",
    "net_test.load_state_dict(torch.load(param['model_dir'], weights_only=True))\n",
    "print('Model loaded successfully!')\n",
    "list_num_spike = []\n",
    "for i in range(10):\n",
    "    list_num_spike.append([0])\n",
    "    list_num_spike[i].append(torch.zeros(param['dim_out']))\n",
    "\n",
    "total_correct = 0  # 전체 맞춘 예측 수\n",
    "total_samples = 0  # 전체 테스트 샘플 수\n",
    "\n",
    "with torch.no_grad():\n",
    "    for img_test, label_test in testloader:\n",
    "        img_test = img_test.reshape(-1, 28 * 28)\n",
    "        spike_num_img_test = torch.zeros(param['batch_size'], param['dim_out']).to(device)\n",
    "        net_test.reset_()  # set the neuron voltage as reset voltage\n",
    "\n",
    "        # using gpu\n",
    "        img_test, label_test = img_test.to(device), label_test.to(device)\n",
    "\n",
    "        # Time-to-first spike coding method\n",
    "        #spike_time = latency(img_test, num_steps=param['T_sim'], tau=10, threshold=0.01, clip=False, normalize=False, linear=False, bypass=True)\n",
    "        spike_time = ttfs_encoding(img_test, param['T_sim'])\n",
    "        mask = torch.ones(param['batch_size'], 1).to(device)\n",
    "        net.reset_()  # set the neuron voltage as reset voltage\n",
    "\n",
    "        for t in range(param['T_sim']):\n",
    "            #new_test_img = spike_time[t]\n",
    "            new_test_img = spike_time[:, :, t]\n",
    "            out_spike, _ = net_test(new_test_img)\n",
    "            out_spike *= mask\n",
    "            spike_num_img_test += out_spike\n",
    "            # update mask\n",
    "            spike_detected = torch.any(out_spike > 0, dim=1, keepdim=True)\n",
    "            mask = mask * (~spike_detected)\n",
    "\n",
    "        pred_label = F.one_hot(spike_num_img_test.max(1)[1], num_classes=10).to('cpu')  # convert the max neuron output index to onehot vector\n",
    "\n",
    "        # Accuracy calculation\n",
    "        pred_label_class = spike_num_img_test.max(1)[1]  # predicted class for each image in the batch\n",
    "        total_correct += (pred_label_class == label_test).sum().item()  # count correct predictions\n",
    "        total_samples += label_test.size(0)  # update total samples\n",
    "\n",
    "        for j in range(label_test.size(0)):\n",
    "            index = label_test[j]\n",
    "            list_num_spike[index][0] += 1\n",
    "            list_num_spike[index][1] += pred_label[j].to('cpu')  # statistics of prediction for every input image\n",
    "\n",
    "# Calculate and print overall accuracy\n",
    "accuracy = total_correct / total_samples * 100\n",
    "print(f'Test Accuracy: {accuracy:.2f}%')\n",
    "\n",
    "# Save confusion matrix\n",
    "with open('confusion_matrix.txt', 'a') as f2:\n",
    "    for i in range(len(list_num_spike)):\n",
    "        s = str(list_num_spike[i][0]) + ' ' + str(list_num_spike[i][1].numpy()).replace('[', '').replace(']', '') + '\\n'\n",
    "        f2.write(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
